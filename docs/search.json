[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"book designed fundamental “-” guide help researchers new systematic review meta-analysis education fields. book focused execute methodologies, statistics driving specific methods. written rather informal format effort help reader connect content.following steps book can help run systematic review meta-analysis successfully, highly recommend learning certain decisions made. example, meta-analysis section book, assume understand happening statistically meta-analysis. explain formulas, main ideas, assumptions, etc. sort depth. plenty resources available help learn information, simply outside current scope book. book currently strictly “-” guide intention make consider “true” statistics book.makes book different others? meta-analysis examples book using standardized mean difference effect sizes (Hedge’s g). lot examples online meta-analysis R using correlations, book created, part, resources find meta-analysis standardized mean differences.","code":""},{"path":"index.html","id":"what-standards-and-packages-does-this-book-align-with","chapter":"Welcome","heading":"What standards and packages does this book align with?","text":"provide guidance relation PRISMA guidelines1 use metafor2 (packages) conducting meta-analyses.","code":""},{"path":"index.html","id":"who-is-this-book-for","chapter":"Welcome","heading":"Who is this book for?","text":"book designed :People just learning systematic review meta-analysis methods.People just learning systematic review meta-analysis methods.People understand meta-analysis, don’t really understand R.People understand meta-analysis, don’t really understand R.People used using graphic user interface (GUI)-based programs conducting meta-analysis, want switch R.People used using graphic user interface (GUI)-based programs conducting meta-analysis, want switch R.Anyone else wants improve knowledge systematic review meta-analytical methods.Anyone else wants improve knowledge systematic review meta-analytical methods.aim book make systematic review, particularly meta-analysis, accessible may fully understand every aspect R want create reproducible analyses, , enjoy free nature R.","code":""},{"path":"index.html","id":"what-will-you-learn","chapter":"Welcome","heading":"What will you learn?","text":"reading book, able :establish research questions inclusion criteriaestablish research questions inclusion criteriaconduct well-documented literature searchconduct well-documented literature searchscreen abstracts studiesscreen abstracts studiesconduct conventional meta-analysis Rconduct conventional meta-analysis Rconduct three-level meta-analysis Rconduct three-level meta-analysis R","code":""},{"path":"index.html","id":"why-does-this-book-exist","chapter":"Welcome","heading":"Why does this book exist?","text":"plethora resources available help learn meta-analysis. even number open-access books help learn meta-analysis R (really enjoyed Meta-Analysis R: Hands-Guide3 Meta-Analysis R Exploring Heterogeneity Using Metaforest.4 find much three-level meta-analysis code book aligns two resources’ recommendations).However, learning meta-analysis R, found lot examples using correlations, whereas many meta-analyses educational sciences use standardized mean difference (SMD) effect size. non-R user, change trivial sounds involves data structures R code. much trial error, finally able learn meta-analyses using metafor R using SMD, well run three-level meta-analysis models.addition, transition GUI-based programs R challenging know code associated R, particularly metafor.5 enjoy coding, always , steep learning curve even . Luckily, lot great resources available online learning R free. one best features using R – much documentation available help learn, costs nothing time. hope book one resources helps others learn use R.","code":""},{"path":"index.html","id":"how-to-use-this-book.","chapter":"Welcome","heading":"How to use this book.","text":"read book, see explain major steps whatever process chapter , provide code analyses appropriate. commented major ideas pieces throughout code examples. certainly statistics book, highlight nuanced, yet important, statistical issues need know conduct meta-analysis R ’re coming GUI-based platform. example, soon see conduct moderator analyses metafor, actually two different Q tests, one tests significant differences levels moderator, one tests moderators significantly different zero. ’ll take look types issues throughout guide.","code":""},{"path":"index.html","id":"disclaimer.","chapter":"Welcome","heading":"Disclaimer.","text":"living book, meaning update time. Please surprised information changes added. addition, please consider code recommendations book exactly , recommendations. may errors /code may work use case. assume liability associated using code information provided throughout book.find errors code text, please email can correct .","code":""},{"path":"index.html","id":"about-the-author.","chapter":"Welcome","heading":"About the author.","text":"name Noah Schroeder, received Ph.D. Educational Psychology program Washington State University. learned meta-analysis using GUI-based programs. taught use R metafor using published papers online resources bored seemed like fun thing . also analyses wanted (three-level meta-analysis) GUI-based programs, run R. areas expertise virtual humans pedagogical agents, multimedia learning, course, review methodologies. Please feel free visit Google Scholar profile.","code":""},{"path":"how-to-cite-this-book.html","id":"how-to-cite-this-book","chapter":"How to Cite this Book","heading":"How to Cite this Book","text":"Please cite book :Schroeder, N. L. (2024). beginner’s guide systematic review meta-analysis. Available https://noah-schroeder.github.io/reviewbook/","code":""},{"path":"introduction-to-systematic-reviews.html","id":"introduction-to-systematic-reviews","chapter":"1 Introduction to Systematic Reviews","heading":"1 Introduction to Systematic Reviews","text":"chapter serves surface level introduction systematic reviews. meant replace proper course learning systematic reviews different types.","code":""},{"path":"introduction-to-systematic-reviews.html","id":"types-of-systematic-reviews","chapter":"1 Introduction to Systematic Reviews","heading":"1.1 Types of Systematic Reviews","text":"Let’s get way early: systematic review umbrella term, containing many types systematically-conducted reviews, well specific methodology. know ’s confusing. think confusing, ’re alone. know know? know ’s confusing see lot scoping reviews published called systematic reviews. scoping reviews conducted systematically, properly labeled scoping reviews. Imagine disappointment expect reading really well-synthesized findings efficacy design intervention instead end reading high-level overview field., types reviews talking talk systematic reviews educational sciences? ’re typically referring scoping reviews (relatively new field (January, 2024), new method), systematic reviews, meta-analyses. Yes, meta-analyses actually type systematic review. fact, methods identical data extraction data analysis. systematic reviews (usually) qualitatively analyze data, meta-analysis quantitatively analyze data. lot different types systematic reviews aware though. recommend reading classic piece Grant Booth (2009)6.Let’s take quick look different types systematic reviews typically see education.","code":""},{"path":"introduction-to-systematic-reviews.html","id":"scoping-reviews","chapter":"1 Introduction to Systematic Reviews","heading":"1.1.1 Scoping Reviews","text":"Scoping reviews tend surface-level overviews field. ’re meant evaluate nature field amount evidence available field. Essentially, help us identify research questions, see gaps literature, help us identify research synthesis needed. Notably - study quality typically examined scoping reviews.Since scoping reviews provide surface-level overview field, helpful? Well, personally think depends field. new fields, certainly. established fields, maybe. depends want review. Perhaps looking see specific methods used, certain aspects intervention investigated. cases scoping reviews can quite helpful. However, ’re seeking find efficacy intervention, design intervention based literature, systematic review meta-analysis ’re likely looking .scoping reviews, please review PRISMA extension scoping reviews (Tricco et al., 2018)7.","code":""},{"path":"introduction-to-systematic-reviews.html","id":"systematic-reviews","chapter":"1 Introduction to Systematic Reviews","heading":"1.1.2 Systematic Reviews","text":"Systematic reviews tend answer specific questions scoping reviews. example, may look efficacy intervention design intervention effective. Typically, systematic review, used method rather umbrella term, refers qualitative analysis data primary studies.Importantly, going conduct systematic review, review PRISMA guidelines (Page et al., 2021)8.","code":""},{"path":"introduction-to-systematic-reviews.html","id":"umbrella-reviews","chapter":"1 Introduction to Systematic Reviews","heading":"1.1.3 Umbrella Reviews","text":"Umbrella reviews systematic reviews reviews. words, collect reviews field synthesize . Pretty cool right? can read Aromataris et al. (2015)9.","code":""},{"path":"introduction-to-systematic-reviews.html","id":"meta-analysis","chapter":"1 Introduction to Systematic Reviews","heading":"1.1.4 Meta-Analysis","text":"Meta-analysis extension systematic review methods, primary difference data analyzed quantitatively rather qualitatively. various types meta-analysis, including conventional (covered book), three-level (covered book), well structural equation modeling meta-analysis (can read ). types well (e.g., Bayesian) ’re common education fields time writing (January, 2024).noted, book don’t explore statistical aspects meta-analysis, ’s -book. can read statistics sources, Meta-Analysis R: Hands-Guide.10 felt Harrer et al. great job making meta-analysis accessible book, interested introduction statistical side meta-analysis, ’s great resource opinion.Importantly, going conduct meta-analysis, review PRISMA guidelines (Page et al., 2021)11. guidelines apply meta-analysis well systematic review.","code":""},{"path":"introduction-to-systematic-reviews.html","id":"non-systematic-reviews","chapter":"1 Introduction to Systematic Reviews","heading":"1.2 Non-Systematic Reviews","text":"Non-systematic reviews typically referred narrative reviews, critical reviews, overviews, etc. purposes book, ’re ignoring literature systematic reviews. ’m saying ’re important. Rather, ’re just talking book.","code":""},{"path":"getting-started.html","id":"getting-started","chapter":"2 Getting Started","heading":"2 Getting Started","text":"’ve decided conduct systematic review meta-analysis. Cool!Now start?","code":""},{"path":"getting-started.html","id":"research-questions","chapter":"2 Getting Started","heading":"2.1 Research Questions","text":"First need set research questions. research questions guide type review conducting. honest, ’ve found book systematic review meta-analysis, ’m guessing already know basics research questions. , let’s look examples types questions may fit different types systematic reviews:Broad questions fit scoping reviews:publication trends field?publication trends field?nature evidence see field?nature evidence see field?type research exists research space?type research exists research space?Specific questions fit systematic reviews:best design virtual humans?best design virtual humans?impact virtual humans learning?impact virtual humans learning?Specific questions fit meta-analyses:impact virtual humans learning?impact virtual humans learning?impact virtual humans motivational outcomes?impact virtual humans motivational outcomes?Wait - question systematic review meta-analysis!Yes . types reviews can used answer question, just differently. systematic review typically qualitatively analyze results, talking trends field. Whereas, meta-analysis quantitatively aggregate results included studies.","code":""},{"path":"getting-started.html","id":"inclusion-and-exclusion-criteria","chapter":"2 Getting Started","heading":"2.2 Inclusion and Exclusion Criteria","text":"Now research questions, need establish inclusion exclusion criteria. define selecting studies included analysis. specific clear reader. reader able apply criteria wanted replicate study. example:Research Question: influence virtual humans learning?Methodological Approach: Three-level meta-analysis.Inclusion criteria: included meta-analysis, studies must:include comparison virtual human non-virtual human condition.include comparison virtual human non-virtual human condition.measure quantified learning outcome.measure quantified learning outcome.report enough data effect size calculation.report enough data effect size calculation.publicly available.publicly available.Exclusion criteria: Studies excluded :used physical robot hologram virtual human.used physical robot hologram virtual human.conducted authentic educational settings.conducted authentic educational settings.accomplish?criteria include studies computer-generated virtual humans physically embodied outside computerized interface, well include studies took place authentic educational settings. studies also enough data around learning outcomes compute effect size.","code":""},{"path":"getting-started.html","id":"what-next","chapter":"2 Getting Started","heading":"2.3 What Next?","text":"Hopefully understand types research questions work well different kinds reviews, well set inclusion criteria. next chapter, need learn PRISMA statement. learn PRISMA start review.","code":""},{"path":"statistical-foundations-of-meta-analysis.html","id":"statistical-foundations-of-meta-analysis","chapter":"3 Statistical Foundations of Meta-Analysis","heading":"3 Statistical Foundations of Meta-Analysis","text":"noted earlier book, intend statistics book. However, want know foundations statistics used book. Others written particularly approachable way. like refer readers Meta-Analysis R: Hands-Guide12 introduction statistical foundations meta-analysis.specific links:Effect SizesPooling Effect SizesBetween-Study HeterogeneityMeta-RegressionThe book Meta-Analysis R: Hands-Guide13 number great chapters advanced meta-analytic methods well, really suggest taking time time read book!","code":""},{"path":"PRISMA.html","id":"PRISMA","chapter":"4 PRISMA","heading":"4 PRISMA","text":"’m going get way now:read PRISMA Statement14, need going forward book.going explain entire PRISMA statement. Please, just read paper15 review PRISMA website.said, let’s check pieces relevant us.","code":""},{"path":"PRISMA.html","id":"what-is-the-prisma-statement","chapter":"4 PRISMA","heading":"4.1 What is the PRISMA statement?","text":"PRISMA statement specifies information reported systematic reviews meta-analyses. Please read . Seriously, please just read paper16 review PRISMA website.","code":""},{"path":"PRISMA.html","id":"what-do-i-need-to-know","chapter":"4 PRISMA","heading":"4.2 What do I need to know?","text":"read paper17 review PRISMA website? , ?review paper18 review PRISMA website, let’s check couple key take-away points.","code":""},{"path":"PRISMA.html","id":"prisma-checklist","chapter":"4 PRISMA","heading":"4.2.1 PRISMA Checklist","text":"now read paper19 reviewed PRISMA website. , know checklist complete reporting review.","code":""},{"path":"PRISMA.html","id":"prisma-flow-chart","chapter":"4 PRISMA","heading":"4.2.2 PRISMA Flow Chart","text":"now read paper20 reviewed PRISMA website. , know flow chart complete reporting review.","code":""},{"path":"PRISMA.html","id":"practical-implications","chapter":"4 PRISMA","heading":"4.3 Practical Implications","text":"’re probably thinking, wow Noah, didn’t say anything PRISMA chapter. ? Well, want read paper21 review PRISMA website. worth time.follow PRISMA statement use checklist flow chart reporting study. ’ll need keep track specific information conduct study. items ’ll want track clearly report methods:exact date literature searchThe exact date literature searchThe exact search terms used database, including limiters filtersThe exact search terms used database, including limiters filtersThe exact databases searchedThe exact databases searchedThe exact number items located databaseThe exact number items located databaseThe total number abstracts located reviewThe total number abstracts located reviewThe total number duplicates removedThe total number duplicates removedThe total number studies excluded title abstract screeningThe total number studies excluded title abstract screeningThe total number studies reviewed full-text screeningThe total number studies reviewed full-text screeningThe total number studies excluded full-text screening reasons , aligned inclusion/exclusion criteriaThe total number studies excluded full-text screening reasons , aligned inclusion/exclusion criteriaThat seems like lot, ’s really difficult. Especially read paper22 reviewed PRISMA website, given templates check list flow chart available. items must reported order transparent review.","code":""},{"path":"PRISMA.html","id":"summary","chapter":"4 PRISMA","heading":"4.4 Summary","text":"risk sounding redundant, please read paper23 review PRISMA website already. serious conducting systematic reviews, time spent reading understanding PRISMA save huge amounts headache study peer-reviewed. Reviewers expect follow report review aligned PRISMA. journals even consider manuscript aligned PRISMA.","code":""},{"path":"literaturesearch.html","id":"literaturesearch","chapter":"5 Literature Searches","heading":"5 Literature Searches","text":"Let’s make one thing clear start talking literature search:literature search flawed, entire systematic review may publishable otherwise useful.means need get step right. Well, ’re honest need get every step right systematic review process, mess literature search, doesn’t matter else done properly, literature search underlies everything else.","code":""},{"path":"literaturesearch.html","id":"create-a-search-string","chapter":"5 Literature Searches","heading":"5.1 Create a Search String","text":"Arguably important part entire review creating good search string. means need include commonly used keywords field. absolute scariest feedback can imagine reviewer something like, “search broad enough. consider important keywords….”. means get start . Sounds fun right? … even remotely fun., can make sure good search string? First, make sure actually know field ’re conducting review . Read papers, gain knowledge. ’ll likely learn keywords used process. Another important step look existing systematic reviews meta-analyses field. keywords use?Keep mind can use sorts strategies search within databases, parentheses, quotation marks, , , asterisks. types strategies function may vary databases generally documentation available tells types operators search supports.","code":""},{"path":"literaturesearch.html","id":"how-broad-or-narrow-should-the-search-be","chapter":"5 Literature Searches","heading":"5.1.1 How broad or narrow should the search be?","text":"totally depends study. fields big. fields small. , part, dictate many studies likely locate. field, common review 800-2000 abstracts, reviews smaller larger. just depends specific topic much literature available.","code":""},{"path":"literaturesearch.html","id":"ways-people-try-to-reduce-the-number-of-studies.","chapter":"5 Literature Searches","heading":"5.1.1.1 Ways people try to reduce the number of studies.","text":"restrict studies published journal articles? quite common, personally prefer practice. greatly limits located, especially certain fields. One may argue, “Well journal articles highest quality ’re peer-reviewed”. Well, ’ve read quite peer-reviewed articles call low-quality, argument doesn’t hold much weight . addition, many conferences, especially printed proceedings, peer-reviewed. , prefer approach reviewing journal articles.limit studies publication date? Maybe - good reason, major breakthrough field changed nature field. Otherwise, , opinion, weak rationale reducing scope search.search whole article titles abstracts search database(s)? Now important question. Personally, prefer search broader possible. However, sometimes practical even though great search string, get tens thousands results. cases, limiting search string needlessly exclude relevant studies, often support searching abstracts studies rather full-text within database. However, cases important search string intentionally designed searching abstracts rather full-text. example, may find need use slightly different search terms really capture relevant studies.","code":""},{"path":"literaturesearch.html","id":"pick-databases","chapter":"5 Literature Searches","heading":"5.2 Pick Databases","text":"pick databases search intentionally, databases choose dictated field study. many search? Well, also depends, can’t give good answer. Lately work educational technology, searching eight databases.","code":""},{"path":"literaturesearch.html","id":"what-about-google-scholar","chapter":"5 Literature Searches","heading":"5.2.1 What about Google Scholar?","text":"Google Scholar bit difficult search way others can replicate , time writing (January, 2024), export citations . , typically formally search Google Scholar, use various combinations keywords informally search Google Scholar, ’ll add relevant studies database located searches. usually categorize something like, “Additional studies located informal searches”.","code":""},{"path":"literaturesearch.html","id":"add-studies-from-existing-reviews","chapter":"5 Literature Searches","heading":"5.3 Add Studies from Existing Reviews","text":"good practice add studies included relevant systematic reviews meta-analyses field database.","code":""},{"path":"literaturesearch.html","id":"record-everything","chapter":"5 Literature Searches","heading":"5.4 Record Everything","text":"noted PRISMA page, record lot details literature search. , information can significant problem peer-review. items record include:exact date literature searchThe exact date literature searchThe exact search terms used database, including limiters filtersThe exact search terms used database, including limiters filtersThe exact databases searchedThe exact databases searchedThe exact number items located databaseThe exact number items located databaseThe total number abstracts located reviewThe total number abstracts located reviewThe total number duplicates removedThe total number duplicates removedThe total number studies excluded title abstract screeningThe total number studies excluded title abstract screeningThe total number studies reviewed full-text screeningThe total number studies reviewed full-text screeningThe total number studies excluded full-text screening reasons , aligned inclusion/exclusion criteriaThe total number studies excluded full-text screening reasons , aligned inclusion/exclusion criteria","code":""},{"path":"literaturesearch.html","id":"exporting-studies-from-databases","chapter":"5 Literature Searches","heading":"5.5 Exporting Studies from Databases","text":"Nearly every database ’ve ever used way mass export located studies. export citations, abstracts, .ris file. record search (keep .ris file) can upload citations citation management system like Zotero, software aid screening like ASReview, Rayyan, Covidence, MetaReviewer. information types software study screening chapter.","code":""},{"path":"literaturesearch.html","id":"building-your-projects-citation-database","chapter":"5 Literature Searches","heading":"5.6 Building Your Project’s Citation Database","text":"Now .ris files databases searched, likely going want combine citation database project. can uploading files citation management system like Zotero, software aid screening like ASReview, Rayyan, Covidence, MetaReviewer.","code":""},{"path":"literaturesearch.html","id":"removing-duplicates","chapter":"5 Literature Searches","heading":"5.6.1 Removing Duplicates","text":"search studies across multiple databases, going duplicate entries, mean, studies come multiple databases. Removing duplicates can incredibly time consuming software assistance. Fortunately, now tools can help, Zotero, ASReview, Rayyan, Covidence.’ve used Zotero years duplicate removal (time writing) can tedious time consuming individually approve duplicate merge. used duplicate removal Rayyan yet. currently (January, 2024) collaborating review using Covidence remove duplicates, far seems helpful. opinion one software “best” “best” vary use case. ’ll just say explore options see preference , certainly pros cons .","code":""},{"path":"screening.html","id":"screening","chapter":"6 Study Screening","heading":"6 Study Screening","text":"point established research question(s), set inclusion criteria, searched databases, located studies, removed duplicates, created database abstracts review. seems like lot, don’t worry, ’re just getting started systematic review process.’s next?Well, need review abstracts see meet inclusion criteria.","code":""},{"path":"screening.html","id":"phases-of-study-screening","chapter":"6 Study Screening","heading":"6.1 Phases of Study Screening","text":"like break study screening two phases, creatively named, Phase Phase II.","code":""},{"path":"screening.html","id":"phase-i-screening","chapter":"6 Study Screening","heading":"6.1.1 Phase I Screening","text":"consider Phase screening title abstract screening. phase, want review titles abstracts studies database see appear meet inclusion criteria . , mark inclusion next phase. , mark exclusion. ’re sure, mark inclusion next phase.’re probably wondering, mark studies? Well bunch different options. One use spreadsheet. abstract screening decade (now use software). just works. also software can help (discussed ).’re done abstract screening, important write many studies excluded. end PRISMA flowchart.","code":""},{"path":"screening.html","id":"abstract-screening-tools","chapter":"6 Study Screening","heading":"6.1.1.1 Abstract Screening Tools","text":"can use simple spreadsheet keep track decisions include exclude studies. usually use Excel file Google Sheet ’m using spreadsheet tracking. created database citation management system, can generally export database .csv. , long databases originally searched exported abstract citation information (hope didn’t forget step!), ’ll everything need, , .csv file. Typically row specific study, ’ll create new column indicate inclusion exclusion. use 1 indicate retaining study, 0 indicate excluding study. way end can sort column get included studies together. ’s simple works.Another option use software like ASReview (free time writing), Rayyan (time writing free version), Covidence (free time writing), MetaReviewer (free time writing). programs well, just four ’m familiar . just completed couple reviews using ASReview Rayyan (January, 2024). Specifically, used ASReview abstract screening Rayyan keep track inclusion exclusion full-text review. really enjoyed using , doesn’t mean work well workflow. limited experience Covidence relatively similar terms features. alas, experience may differ software programs tend change relatively frequently. Consequently, recommendation try different options see works best workflow.","code":""},{"path":"screening.html","id":"phase-ii-screening","chapter":"6 Study Screening","heading":"6.1.2 Phase II Screening","text":"’ve reviewed abstracts now set studies might meet inclusion criteria. First, let’s write many studies left. end PRISMA flow chart.Next really fun task locating full text studies need reviewed. taught save files using naming convention ‘FirstauthorlastnameSecondauthorlastnameYear’. example, Schroeder Kucera (2022)24 saved SchroederKucera2022. system worked really well don’t see changing .time time, may able locate full text study. , write many couldn’t locate. also go PRISMA flowchart.next step really easy: review full-text study see meets inclusion criteria . However, keep track study excluded, summary numbers go PRISMA flow chart. reasons related inclusion exclusion criteria.","code":""},{"path":"screening.html","id":"inter-rater-reliability-or-agreement","chapter":"6 Study Screening","heading":"6.2 Inter-rater Reliability or Agreement","text":"need calculate inter-rater agreement inter-rater reliability anytime one coder involved screening process. Generally speaking, see 10-20% sample dual coded inter-rater agreement reliability purposes. 20% call “standard”, smaller percentages occasionally used larger reviews.calculate ? Well, depends calculating. Many times see simple inter-rater agreement statistic reported percentage. OK. Cohen’s kappa another option two raters. ’ve also seen correlation coefficients reported. appropriate depends study data.","code":""},{"path":"screening.html","id":"automation-tools","chapter":"6 Study Screening","heading":"6.3 Automation Tools","text":"time writing (January, 2024), seeing rise AI-assisted abstract screening. number different software platforms can aid . good idea? Time tell. relying AI-assisted screening, AI-exclude studies based algorithms, recommend looking evidence software works well use case. type work exists literature can help guide types software works best, different algorithms perform different scenarios. recently (January, 2024) used ASReview reading preprint Campos et al. (2023)25. Overall, using ASReview positive experience us, likely screened studies read findings Campos et al. (2023)26. One benefit AI-assisted screening however ability move relevant studies first. Even abstracts reviewed, process alone likely save screener time.","code":""},{"path":"data.html","id":"data","chapter":"7 Data Extraction and Coding","heading":"7 Data Extraction and Coding","text":"Preface chapter: many factors account coding impossible say, “just ” ’ll get data need. , chapter cover major ideas, may need refer reviews area practical examples.","code":""},{"path":"data.html","id":"general-principles-and-ideas","chapter":"7 Data Extraction and Coding","heading":"7.1 General Principles and Ideas","text":"","code":""},{"path":"data.html","id":"coding-forms","chapter":"7 Data Extraction and Coding","heading":"7.1.1 Coding Forms","text":"point identified studies, now need get data studies format can use data analysis. Typically used spreadsheets “coding form” store data. used SPSS, Excel, Google Sheets. advantages disadvantages. Recently, ’ve using Google Sheets simply easily accessible. really find missing features software platforms ’ve tried.’re conducting meta-analysis, perhaps important consideration can export file type usable R. Personally prefer use .csv files data file import R. ? examples found online used first learned R, ’ve used ever since.  ","code":""},{"path":"data.html","id":"establishing-your-variables","chapter":"7 Data Extraction and Coding","heading":"7.1.2 Establishing Your Variables","text":"Next need decide information want extract studies. sounds daunting, many possibilities! Well, actually pretty easy. Just look research questions - help identify information need extract studies.One important factor keeping table variables ’re coding. like create table first column name variable, second column explanation coding scheme. example:","code":""},{"path":"data.html","id":"systematic-review-outcome-data-extraction","chapter":"7 Data Extraction and Coding","heading":"7.2 Systematic Review Outcome Data Extraction","text":"difficult provide guidance set coding form systematic reviews simply many different options. example, want know fine-grained results, mean, standard deviations, sample sizes? want just know overall statistical test results? , maybe care conclusion authors made based findings?Regardless, ’ll probably key features want code studies. Depending research questions, can vary widely. example, might interested publication trends, coding year type publication. , might interested design intervention, coding features implementation. , might interested type assessment used code qualities. , might code things. really depends research questions. research questions guide data extract studies.","code":""},{"path":"data.html","id":"meta-analysis-outcome-data-extraction","chapter":"7 Data Extraction and Coding","heading":"7.3 Meta-Analysis Outcome Data Extraction","text":"Metafor27 uses two pieces information conducting meta-analysis need consider coding process: effect size (yi) variance (vi). , choices coding: can code mean, standard deviation, sample size experimental control groups use R metafor calculate effect size variance comparison (recommended method), can calculate effect size variance effect size . prefer former approach find helpful data check errors coding (misplaced decimal point – things happen!) also calculating sample sizes tables.choose use R metafor calculate effect sizes variance, important mean, standard deviation, sample size experimental group control group columns (.e., ’ll need six columns record data). analysis codes book assume case. recommend simple column titles descriptive, don’t contain spaces, easy remember, type R.Another important note like make, see poorly reported papers sometimes, purposeful selection comparison groups. Personally, recommend given choice (e.g., multiple control /experimental groups), select comparisons fewest confounding variables. ? confidence effects find actually speaking intervention ’re investigating rather extraneous factors. given choice, generally choose ignore (’s right, ignore data!) groups present confounding variables non-confounded comparison available. ‘leaves data table’ speak, makes trustworthy analysis (opinion). One key thing remember meta-analysis use junk data, ’ll get junk result. data isn’t necessarily better “cleaner” (less confounded) data.","code":""},{"path":"data.html","id":"conventional-meta-analysis","chapter":"7 Data Extraction and Coding","heading":"7.3.1 Conventional Meta-analysis","text":"One key assumption conventional meta-analysis statistical independence - participant can counted . Let’s say study three dependent variables, interest - guess , conventional meta-analysis, pick one dependent variable (calculate weighted means pooled standard deviations, prefer method reasons discussed conventional meta-analysis chapter). Due , comparison appear one row coding form.Let’s look examples different scenarios. Please note can many moderator variables wish, can continuous categorical.first example study one experiment three groups: control group, group using clickers, group using clickers self-reflection prompts. purposes example, ’ll ignore clicker self-reflection prompts group, ) one control group, can one comparison violate principle statistical independence, b) don’t like combine groups reasons discussed conventional meta-analysis chapter. means ’ll compare control group clicker group. ’ll also code two moderator variables, type control condition (categorical) student’s confidence level using clickers (continuous). coding form may look like :’s mean?Labels “Study” column appear forest plots, check spelling formatting unless want fix later. (Unsolicited advice: nobody wants fix something like later, just type correctly first time).Comparison case used know group’s data coded readers know data coded.Control categorical moderator. set choices starting coding.Confidence continuous variable.Exp_mean = mean experimental groupExp_sd = standard deviation experimental groupExp_n = sample size experimental groupCtrl_mean = mean control groupCtrl_sd = standard deviation control groupCtrl_n = sample size control groupNotes = notes paperWhat study design two control groups (purposes) two experimental groups? Well, luckily can include . ’s might look like participants split low confidence high confidence participants:’s mean?can see differences compared first example. Namely, study column separated study names adding ‘’ ‘b’ indicate different comparisons study.Next, “comparison” indicated one group designated low confidence participants, one high confidence. Importantly - different participant groups overlap.’s basically . important thing remember coding conventional meta-analysis participant can counted .","code":""},{"path":"data.html","id":"three-level-meta-analysis","chapter":"7 Data Extraction and Coding","heading":"7.3.2 Three-Level Meta-Analysis","text":"explained three-level meta-analysis chapter, three-level meta-analysis can account dependencies data. , remember example study three dependent variables important? Well, use three-level meta-analysis can include data!important things note structure coding form. best seen example, let’s analyze example coding form. Note just like conventional meta-analysis, can many moderator variables wish, can continuous categorical.’s mean?ES_number: column unique three-level meta-analysis. sequentially number every comparison coding form. duplicates.Study: Similar conventional meta-analysis, citation information want appear forest plot. However, unlike conventional meta-analysis, want study name identical across comparisons (rows) data study.Comparison: Similar conventional meta-analysis, tells us information specifically examined. indicated type outcome test (.e., recall, transfer, performance).Control: categorical moderator pre-set categories.Confidence: continuous moderator. Note comparisons participants across three rows. huge violation statistical independence conventional meta-analysis, ’s ’re using three-level meta-analysis!rest columns conventional meta-analysis example.","code":""},{"path":"data.html","id":"inter-rater-reliability-or-agreement-1","chapter":"7 Data Extraction and Coding","heading":"7.4 Inter-rater Reliability or Agreement","text":"need calculate inter-rater agreement inter-rater reliability anytime one coder involved data extraction process. Even one person coding data, still second coder independently code subset studies. ? can find ) first rater accurate, b) coding scheme makes sense another person, c) ensure coding scheme reliable. Generally speaking, see 10-20% sample dual coded inter-rater agreement reliability purposes. 20% call “standard”, smaller percentages occasionally used larger reviews.calculate ? Well, depends calculating. Many times see simple inter-rater agreement statistic reported percentage. OK. Cohen’s kappa another option two raters. ’ve also seen correlation coefficients reported. appropriate depends study data.","code":""},{"path":"data.html","id":"summary-1","chapter":"7 Data Extraction and Coding","heading":"7.5 Summary","text":"single important consideration coding coding meta-analysis selection comparisons. want violate principle statistical independence conventional meta-analysis, don’t want introduce confounding variables type meta-analysis.","code":""},{"path":"systematic-review-data-analysis.html","id":"systematic-review-data-analysis","chapter":"8 Systematic Review Data Analysis","heading":"8 Systematic Review Data Analysis","text":"chapter going really short. ? Well, analyze systematic review data, ’re typically looking themes data. honest, don’t much say . However, couple things recommend:start analyzing data, make spreadsheet research question, move relevant data . sure keep master coding form intact though!start analyzing data, make spreadsheet research question, move relevant data . sure keep master coding form intact though!Looking patterns can difficult. Remember many spreadsheet programs sorting features may help identify surface-level patterns.Looking patterns can difficult. Remember many spreadsheet programs sorting features may help identify surface-level patterns.Cross-tabulation can great way look interesting interactions data points.Cross-tabulation can great way look interesting interactions data points.’s really say . ’re really looking patterns relation research question. need guidance , suggest reviewing wonderful resources written analyzing qualitative data , example, content analysis thematic analysis. may helpful getting started feel overwhelmed data.","code":""},{"path":"rbasics.html","id":"rbasics","chapter":"9 R Basics","heading":"9 R Basics","text":"Alright, ’re getting good stuff , use R. might bit anxious R requires coding, don’t worry, ’ll walk everything step step.","code":""},{"path":"rbasics.html","id":"why-use-r-when-a-gui-based-platform-is-easier","chapter":"9 R Basics","heading":"9.1 Why use R when a GUI-based Platform is Easier?","text":"time writing, GUI-based platforms Comprehensive Meta-Analysis (paid software time writing), JASP (free software time writing), Jamovi (free software time writing) excellent conducting conventional meta-analyses. can help analyze data quickly, without know coding R. However, options limited terms reproducibility, meaning someone need program confirm analysis. may seem like minor limitation , actually quite important.Another limitation many GUI-based platform (time writing) allow one conduct multivariate three-level meta-analyses, among limitations. educational sciences, three-level meta-analysis seems offer advantages can account , example, learning outcome tests study rather one learning outcome test per study. words, three-level meta-analysis can account dependence effect sizes, whereas conventional (two-level) meta-analysis . factor alone convinced needed learn R!One final thing found enjoyed learning R metafor28 taught just much may realize might happening behind scenes GUI-based software. example, know estimator ’re using GUI-based software? using Knapp-Hartung adjustment? kinds questions important, yet may think just copy-pasted data asked software run analysis.Let’s get started using R.","code":""},{"path":"rbasics.html","id":"install-r-and-r-studio","chapter":"9 R Basics","heading":"9.2 Install R and R Studio","text":"can download install R recommend downloading installing R Studio (free version) well.R R Studio installed, ’ll want open R Studio.","code":""},{"path":"rbasics.html","id":"what-you-need-to-know","chapter":"9 R Basics","heading":"9.3 What You Need to Know","text":"think need know R R Studio continuing book? Well, honestly lot. ’ve tried break simple terms. install R R Studio, continue book long know enter code file ’re working (top left R Studio ), console (bottom left R Studio ), environment (top right R Studio ), files plots appear (bottom right R Studio ). understand big ideas, think ’ll likely OK move forward. ’s screenshot R Studio can see everything set (believe default).","code":""},{"path":"rbasics.html","id":"set-your-working-directory","chapter":"9 R Basics","heading":"9.3.1 Set Your Working Directory","text":"’ll need tell R save files retrieve files , known working directory. simplicity, set new project folder desktop, save data file . set folder working directory. set working directory, click session, set working directory, seen screenshot . choose “choose directory” option, choose desktop folder project folder.","code":""},{"path":"rbasics.html","id":"install-r-packages-well-need-for-meta-analysis","chapter":"9 R Basics","heading":"9.3.2 Install R Packages We’ll Need for Meta-Analysis","text":"’ll need install R packages continuing book. Fortunately, super easy! Let’s see .file (see screenshot ) want enter following code:code ?code install named packages computer R understands functions built one.get actually install run code?Now ’ve copy-pasted code file, want highlight code, click ‘run’ top right file area. See screenshot , run highlighted red.click run, ’ll see things appear console. ’s normal. take minutes packages install, ’re done, ’re ready move forward. package installed, don’t need install every time run analysis. just open . don’t know , don’t worry, ’ll walk go chapter.","code":"\n#install packages\ninstall.packages(\"metafor\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"plyr\")\ninstall.packages(\"grid\")\ninstall.packages(\"gridExtra\")\ninstall.packages(\"metaSEM\")\ninstall.packages(\"ggrepel\")"},{"path":"rbasics.html","id":"was-that-easy","chapter":"9 R Basics","heading":"9.3.2.1 Was that easy?","text":"first step easy figured without much trouble, think ’re ready move forward book. meta-analysis codes sections book rely copy-pasting sections code book R Studio interface, highlighting relevant section code just copy-pasted R Studio, clicking ‘run’.","code":""},{"path":"rbasics.html","id":"was-this-too-difficult","chapter":"9 R Basics","heading":"9.3.2.2 Was this too difficult?","text":"struggled keep far, suggest start basics. many resources online, don’t see reason rewrite others written extensively. know getting started R Studio can intimidating. seems scary complicated. get started start writing code, won’t seem scary. starting point: https://education.rstudio.com/learn/beginner/scary R become? Well, may surprised hear wrote entire book R Studio using bookdown package. R versatile!","code":""},{"path":"meta.html","id":"meta","chapter":"10 Conventional Meta-Analysis","heading":"10 Conventional Meta-Analysis","text":"chapter cover basics conventional (two-level) meta-analysis R using metafor.29 conventional meta-analysis, important limitation known principle statistical independence, meaning participant can counted . mean researcher?Let’s look example: Say comparing impact computer learners’ reading proficiency compared media. found study meets inclusion criteria three groups: computer group, tablet group, paper book group. can see two possible comparisons : computer vs tablet, computer vs paper book. may think can include comparisons conventional meta-analysis. However, incorrect. count computer group twice, therefore violating principle statistical independence. , must make decision: comparison want include? Alternatively, (wouldn’t) take weighted mean pooled standard deviation two non-computer groups create comparison duplicate computer group’s scores. say latter approach add conflating factors analysis. Remember - meta-analysis useful types data went !Another popular issue question fixed effects random effects models. Simply stated, almost always use random effects models education, examples book use random effects. don’t know differences fixed random effects meta-analysis models, please see.30If aren’t familiar conventional meta-analysis, please read conducting one. plenty free resources available. recommend starting great, free book, Meta-Analysis R31.Let’s say understand differences conventional three-level meta-analytic models, understand meta-analysis used , ’ve decided ’re moving ahead conventional model. Let’s explore R metafor32 using standardized mean differences effect size.","code":""},{"path":"meta.html","id":"preparing-your-data","chapter":"10 Conventional Meta-Analysis","heading":"10.1 Preparing your data","text":"Hopefully already run literature search, screened studies, extracted data. point forward assumes already completed steps.","code":""},{"path":"meta.html","id":"your-data-file","chapter":"10 Conventional Meta-Analysis","heading":"10.1.1 Your Data File","text":"Personally prefer use .csv files data file import R. ? ’s always used examples found online learning R, ’ve used ever since. change something works? Plus, .csv works many different software programs across various operating systems.  noted data extraction coding chapter, metafor uses two pieces information conducting meta-analysis need consider importing data R: effect size (yi) variance (vi). read previous chapters, know choices coding: can code mean, standard deviation, sample size experimental control groups use R metafor calculate effect size variance comparison (recommended method), can calculate effect size variance effect size . prefer former approach find helpful data check errors coding (misplaced decimal point – things happen!) also calculating sample sizes tables.choose use R metafor calculate effect sizes variance, important mean, standard deviation, sample size experimental group control group columns. recommend simple column titles descriptive easy remember, type R. See sample coding form , use conventional meta-analysis. Note can many moderator variables wish, can continuous categorical., assuming done, let’s get onto fun stuff, running conventional meta-analysis!","code":""},{"path":"meta.html","id":"running-a-conventional-meta-analysis-with-metafor","chapter":"10 Conventional Meta-Analysis","heading":"10.2 Running a Conventional Meta-Analysis with Metafor","text":"","code":""},{"path":"meta.html","id":"example-data-for-this-analysis","chapter":"10 Conventional Meta-Analysis","heading":"10.2.1 Example Data for This Analysis","text":"want follow along specific example, ’ll want use subset data Schroeder Cenkci’s (2018)33 meta-analysis spatial split-attention effect. data can downloaded .","code":""},{"path":"meta.html","id":"load-r-packages","chapter":"10 Conventional Meta-Analysis","heading":"10.2.2 Load R Packages","text":"First need load R packages. Hopefully installed already, won’t take long, just see R Basics chapter. Assuming already installed R packages, let’s load can meta-analysis!’s code ?code simply loading metafor package R environment can analysis. ’s also loading tidyverse, ’ll use help us calculate participant numbers create tables.","code":"\n#load metafor\nlibrary(metafor)\nlibrary(tidyverse)"},{"path":"meta.html","id":"import-your-data-into-r-studio","chapter":"10 Conventional Meta-Analysis","heading":"10.2.3 Import Your Data Into R Studio","text":"first step conducting meta-analysis read data. , first want set working directory (R Basics chapter). ’ve set working directory saved SC sample data file , can use piece code.’s code ?see first piece code ‘dat’, going name data file. <- indicates going name something. next piece telling R read .csv file working directory, can see file name used. basically, ’re saying import data .csv file call dat.run , ’ll see item called ‘dat’ appear environment, contains data!","code":"\n#name data file and read in .csv. \ndat <- read.csv(\"SC sample data.csv\")"},{"path":"meta.html","id":"calculating-effect-sizes","chapter":"10 Conventional Meta-Analysis","heading":"10.2.4 Calculating Effect Sizes","text":"Next, want calculate effect sizes variance effect size done already. can using code:’s code ?dat1 <- indicates naming new datafile.case ’re calculation, Escalc telling calculate effect size. Within function, measure=“SMD” saying want use standardized mean difference.next set variables (m1i, sd1i, n1i, m2i, sd2i, n2i) specific pieces information metafor needs calculate effect size. m1i mean intervention group. sd1i standard deviation intervention group. n1i sample size intervention group. m2i mean control group. sd2i standard deviation control group. n2i sample size control group. always found codes hard remember, coding form/data file use different column headings. can see tell metafor find variable using = sign. example, mean intervention group (m1i) called Exp_mean data file.Finally, need tell metafor find data, refer data already R. use datafile ‘dat’.Now can make sure effect size variance effect size calculated:’s code ?display full data set saved ‘dat1’ console.However, find kind hard read lot data. , prefer write .csv file instead find easier read. code can :’s code ?write.csv tells R want create .csv file. saved working directory.dat1 telling R data want write .csv file.file = “ESdata.csv” simply naming datafile whatever ” “. can name whatever want, example use ESdata file name, ’ll assume case rest analysis.’re probably wondering, write .csv file effect size variance data saved R?Well, like look .csv file make sure don’t see effect sizes seem wrong. find easy track back study came can see made mistake coding. misplaced decimal point can huge implications analysis - step helps catch human errors.","code":"\n#calculate overall ES, in this case standardized mean difference (Hedges g), and variance.\n\ndat1 <- escalc(measure=\"SMD\", m1i=Exp_mean, sd1i=Exp_sd, n1i=Exp_n, m2i=Ctrl_mean, sd2i=Ctrl_sd, n2i=Ctrl_n, data=dat)\n#display data\ndat1\n#save .csv file with ES data. This goes into working directory\nwrite.csv(dat1, file = \"ESdata.csv\")"},{"path":"meta.html","id":"running-the-meta-analysis-model","chapter":"10 Conventional Meta-Analysis","heading":"10.3 Running The Meta-Analysis Model","text":"Now part ’ve waiting , let’s run meta-analysis model! can use code:’s code ?First, ’re naming meta-analysis result new piece data R, ’re naming ‘overallresult’rma telling metafor want run random-effects, conventional meta-analysis model. Within , ’re using yi reference effect size data within data set (column heading), vi reference effect size variance within data set (column heading), data = dat1 simply telling metafor data set within R reference running analysis. Note ’re using dat1, rather dat, dat1 contains effect sizes variances calculated, whereas dat .ran code …. seemingly nothing happened? Well, look environment, ’ll see new item called overall result. Let’s view console now can see overall result meta-analysis:’s code ?code simply displays result console can see meta-analysis result.","code":"\n#run overall random effects meta-analysis\noverallresult <- rma(yi, vi, data=dat1)\n#display meta-analysis result\noverallresult"},{"path":"meta.html","id":"interpreting-the-results","chapter":"10 Conventional Meta-Analysis","heading":"10.3.1 Interpreting the Results","text":"run code, now see following:’s mean?Recall subset data Schroeder Cenkci (2018)34, numbers align published version.first line tells us random-effects model including 27 comparisons, tau2 estimated using restricted maximum likelihood estimation (REML).Typically, important pieces interested reporting manuscript overall effect size, Q-test, I2.effect size (estimate model results) interpreted standardized mean difference effect size, significant Q test indicates significant heterogeneity sample, I2 statistic gives us percentage commonly used report -study heterogeneity.","code":"Random-Effects Model (k = 27; tau^2 estimator: REML)\n\ntau^2 (estimated amount of total heterogeneity): 0.2372 (SE = 0.0940)\ntau (square root of estimated tau^2 value):      0.4870\nI^2 (total heterogeneity / total variability):   73.51%\nH^2 (total variability / sampling variability):  3.77\n\nTest for Heterogeneity:\nQ(df = 26) = 90.0975, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.6142  0.1127  5.4512  <.0001  0.3934  0.8351  *** \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ .05 ‘.’ 0.1 ‘ ’ 1"},{"path":"meta.html","id":"checking-for-outliers-and-influence","chapter":"10 Conventional Meta-Analysis","heading":"10.3.2 Checking for Outliers and Influence","text":"point ’ve ran random-effects meta-analysis model. However, checked outliers studies significant influence results. actually complex topic, many meta-analyses (January, 2024) education actually address ) searched outliers influence, b) metric used check outliers , c) outliers . Kinda interesting right?’s can check outliers influence. ’ll follow Viechtbauer Cheung’s (2010)35 process, fortunately built right metafor. Similarly, also know website describes function ’ll use.’s code ?tells metafor produce influence diagnostics meta-analysis model (called ‘overallresult’ earlier step).run , ’ll see bunch data console. ’ll look like :’s result mean?data looks scary first, ’s actually really easy interpret. ? Well, check last column labeled ‘inf’. tells us studies outliers significantly influenced results. can see study 9 potentially outlier significant influence result. can read influence diagnostics metrics used Viechtbauer Cheung (2010)36.know data study 9 dataset potential outlier significant influence result. ? Well, ’s lot options, recommended steps:Go back data check effect size. oddly large small? , check see typo data.Go back data check effect size. oddly large small? , check see typo data.Let’s say data errors. Next ’ll look study . something substantially methodologically ‘wrong’ significantly different studies sample? , may able rationalize removing study data set. remove , sure report , , manuscript.Let’s say data errors. Next ’ll look study . something substantially methodologically ‘wrong’ significantly different studies sample? , may able rationalize removing study data set. remove , sure report , , manuscript.Ok now things get real: Let’s say data good, study pretty well-done notably different studies sample. ? Well, ’s matter opinion.\ncurrent personal opinion generally retain study - valid data.\nAnother option “downsize” effect size slightly larger (smaller) next largest (smallest) effect size.\ndon’t prefer approach think valid data examined valid data, reasonable option. problem approach never seen metric much “larger” “smaller” change effect size . guess just… guess? seems imprecise since can/influence whole analysis, don’t like .\n\nfinal option remove outlier dataset.\ngenerally don’t like option rationalize study consistent rest analysis.\n\nOk now things get real: Let’s say data good, study pretty well-done notably different studies sample. ? Well, ’s matter opinion.current personal opinion generally retain study - valid data.current personal opinion generally retain study - valid data.Another option “downsize” effect size slightly larger (smaller) next largest (smallest) effect size.\ndon’t prefer approach think valid data examined valid data, reasonable option. problem approach never seen metric much “larger” “smaller” change effect size . guess just… guess? seems imprecise since can/influence whole analysis, don’t like .\nAnother option “downsize” effect size slightly larger (smaller) next largest (smallest) effect size.don’t prefer approach think valid data examined valid data, reasonable option. problem approach never seen metric much “larger” “smaller” change effect size . guess just… guess? seems imprecise since can/influence whole analysis, don’t like .final option remove outlier dataset.\ngenerally don’t like option rationalize study consistent rest analysis.\nfinal option remove outlier dataset.generally don’t like option rationalize study consistent rest analysis.purposes example, ’ll assume data good, nothing particularly notable study . Therefore retain effect size data.","code":"\n#check for outliers\ninfluence(overallresult)  rstudent  dffits cook.d  cov.r tau2.del  QE.del    hat weight    dfbs inf \n1    0.6685  0.1352 0.0188 1.0679   0.2458 87.9029 0.0394 3.9410  0.1353     \n2    0.9087  0.1928 0.0375 1.0537   0.2399 84.8441 0.0432 4.3182  0.1929     \n3    0.5790  0.1083 0.0120 1.0629   0.2462 88.9252 0.0336 3.3650  0.1081     \n4   -1.5995 -0.3258 0.0986 0.9709   0.2146 81.8692 0.0397 3.9747 -0.3253     \n5   -0.5008 -0.1096 0.0126 1.0913   0.2509 88.7138 0.0464 4.6375 -0.1100     \n6   -0.5864 -0.1030 0.0108 1.0550   0.2451 89.5042 0.0296 2.9570 -0.1027     \n7   -0.9935 -0.2231 0.0498 1.0501   0.2371 81.6753 0.0480 4.8003 -0.2231     \n8    1.3164  0.2661 0.0684 1.0066   0.2262 83.0741 0.0391 3.9107  0.2659     \n9    3.7924  0.6914 0.3325 0.6777   0.1237 61.5550 0.0340 3.4049  0.7120   * \n10  -0.2785 -0.0576 0.0035 1.0906   0.2525 89.9252 0.0412 4.1216 -0.0577     \n11   0.3018  0.0598 0.0037 1.0827   0.2511 89.5783 0.0379 3.7881  0.0598     \n12   0.2050  0.0421 0.0019 1.0918   0.2530 89.7261 0.0409 4.0860  0.0421     \n13  -0.4720 -0.0961 0.0096 1.0802   0.2496 89.4834 0.0399 3.9877 -0.0962     \n14  -1.0632 -0.2193 0.0478 1.0359   0.2351 86.1101 0.0408 4.0790 -0.2193     \n15   0.0796  0.0165 0.0003 1.0966   0.2541 89.9615 0.0422 4.2171  0.0165     \n16   0.0159  0.0028 0.0000 1.0733   0.2502 90.0770 0.0319 3.1859  0.0028     \n17   1.3506  0.2737 0.0721 1.0025   0.2249 82.6657 0.0393 3.9277  0.2735     \n18   0.5500  0.1096 0.0124 1.0730   0.2479 88.6613 0.0383 3.8253  0.1096     \n19   0.3245  0.0610 0.0039 1.0737   0.2496 89.6452 0.0340 3.4041  0.0609     \n20   0.4078  0.0775 0.0062 1.0724   0.2489 89.4124 0.0347 3.4717  0.0773     \n21  -0.3888 -0.0719 0.0053 1.0689   0.2485 89.8413 0.0327 3.2714 -0.0718     \n22  -0.6555 -0.1428 0.0211 1.0797   0.2474 87.7178 0.0458 4.5805 -0.1433     \n23  -0.0092 -0.0020 0.0000 1.0920   0.2534 90.0749 0.0400 3.9967 -0.0020     \n24  -1.5371 -0.2464 0.0592 0.9875   0.2247 86.1028 0.0257 2.5745 -0.2480     \n25   0.7452  0.1174 0.0139 1.0383   0.2416 88.9126 0.0240 2.4018  0.1171     \n26  -1.6889 -0.2854 0.0780 0.9711   0.2184 84.7843 0.0287 2.8680 -0.2875     \n27  -1.0243 -0.1771 0.0313 1.0289   0.2369 88.1449 0.0290 2.9037 -0.1771"},{"path":"meta.html","id":"writing-up-the-results","chapter":"10 Conventional Meta-Analysis","heading":"10.3.3 Writing up the Results","text":"going write , may report something like :conducted random-effects meta-analysis 27 independent comparisons. results indicated intervention significantly better control condition (g = .61, p < .001). Moreover, model indicates significantly heterogeneity within sample (Q(26) = 90.10, p < .001), 73.51% variance within sample due -study heterogeneity. detected one study potential outlier significant influence overall effect size, however examination study indicate notable deviations studies sample. , study retained data analysis.","code":""},{"path":"meta.html","id":"forest-plots","chapter":"10 Conventional Meta-Analysis","heading":"10.3.4 Forest Plots","text":"always include forest plot results. can create one code:’s code ?code complex, can look bigger pieces . first line setting ‘forestplotdetails’ named data R environment. ’re referencing function metafor (forest.rma) telling use data ‘overallresult’, meta-analysis result R environment. Next see ‘slab=paste….’ telling metafor dataset use (dat1). $studyauthor tells metafor get data fill Author Year column dataset. ‘main’ ‘header’ headings forest plot.rest code complex specifics setting specific titles. copy-pasted example code found online worked . may find need move text positions, forestplotdetails data might helpful.code works correctly , forest plot appear plots section R studio. can save clicking export (toolbar plot), following options save file.","code":"\n#forest plot run this entire code section together. \nforestplotdetails<-forest.rma(overallresult, slab=paste(dat1$studyauthor), main = \"Forest Plot of Observed Effects\", header=\"Author(s) and Year\")\n#this sets the text labels. first text position is X axis, second is y. \nop <- par(cex=.75, font=2)\ntext(-7.75, 60, \"Authors and Year\", pos=4)\ntext(10, 60, \"Effect Size (g) [95% CI]\", pos=2)\npar(op)\nforestplotdetails ##this will print details for forest plot size which helps with text location"},{"path":"meta.html","id":"moderator-analysis","chapter":"10 Conventional Meta-Analysis","heading":"10.3.5 Moderator Analysis","text":"’ve ran overall random-effects meta-analysis model. people think important finding, education, think result generally kind interesting. really good stuff, opinion, examining potential moderator variables. Essentially, ’re going check see variables may influence overall effect size.might moderator variable? Well, depends field intervention ’re investigating. educational technologies, typically examine participant characteristics, study characteristics, intervention characteristics potential moderators., let’s get right ! ’re going focus categorical moderators plethora resources online run continuous moderators.WARNING: run categorical moderator analysis metafor actually two steps look similar. Let’s take look different steps.","code":""},{"path":"meta.html","id":"calculate-qbetween","chapter":"10 Conventional Meta-Analysis","heading":"10.3.5.1 Calculate Qbetween","text":"First need calculate Qbetween. omnibus test tell us significant differences levels moderator. ’re going use grade range example:’s code ?first line first creating piece data R, ’re naming mod.gradeq (, stands moderator, grade, qbetween, can name whatever want). Next ’ll see familiar rma code, new piece ‘mods = ~ factor(graderange)’ piece. saying want run moderator analysis graderange (’s column name data set) moderator.second line simply displays data screen.run code, ’re presented following:’s result mean?’s lot information want one thing: test moderators. case, ’s Test Moderators (coefficients 2:5): QM(df = 4) = 4.2829, p-val = 0.3691What ’re checking p value. can see test significant, means statistically significant moderator. words, example, effects intervention significantly different participants K-5 participants Post-Secondary Education.Qbetween value hand, now need create actual table ’ll report manuscript. ’ll note calculated Qbetween, one levels moderator missing, replaced term intercept. Well, ’s time fix get tables use reporting manuscript.’ll use similar code:’s code ?first line first creating piece data R, ’re naming mod.grade (, stands moderator, grade, can name whatever want). Next ’ll see familiar rma code, ‘mods = ~ factor(graderange)’ piece. saying want run moderator analysis graderange (’s column name data set) moderator. ’s new -1, removes intercept runs ANOVA type model ’re used seeing categorical variables educational meta-analyses.second line simply displays data screen.run code, ’ll get results, look like :’s result mean?looks almost identical previous result calculated Qbetween. However, ’ll note intercept now gone instead levels moderator listed (case, different grade ranges). means, standard errors, p values, etc. want report manuscript.Note test moderators different . Confusing right? Well, ’s two tests, named thing, testing different things. calculated Qbetween, test moderators testing significant differences levels moderator. However, test moderators testing moderators significantly different zero. totally different tests - use test moderator Qbetween value certainly !moderator variables test? Well, simply replace ‘graderange’ variable whatever moderator variable column data labeled , don’t forget rename data items well (mod.gradeq mod.grade). can re-run two code sets calculate Qbetween effect sizes.","code":"\n#moderator test to calculate qbetween value. \nmod.gradeq <- rma(yi, vi, mods = ~ factor(graderange), data=dat1)\n#Display moderator Qbetween result\nmod.gradeqMixed-Effects Model (k = 27; tau^2 estimator: REML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.2302 (SE = 0.1006)\ntau (square root of estimated tau^2 value):             0.4798\nI^2 (residual heterogeneity / unaccounted variability): 72.28%\nH^2 (unaccounted variability / sampling variability):   3.61\nR^2 (amount of heterogeneity accounted for):            2.96%\n\nTest for Residual Heterogeneity:\nQE(df = 22) = 75.7955, p-val < .0001\n\nTest of Moderators (coefficients 2:5):\nQM(df = 4) = 4.2829, p-val = 0.3691\n\nModel Results:\n\n                                                                     estimate      se     zval    pval    ci.lb   ci.ub \nintrcpt                                                                0.6096  0.3216   1.8956  0.0580  -0.0207  1.2400 \nfactor(graderange)Grades K-5                                          -0.4136  0.4911  -0.8423  0.3996  -1.3761  0.5489 \nfactor(graderange)Not Stated                                          -0.5549  0.5093  -1.0895  0.2759  -1.5531  0.4433 \nfactor(graderange)Other (combined grades)                              0.3815  0.6470   0.5896  0.5555  -0.8866  1.6495 \nfactor(graderange)Post-Secondary (Undergraduate/Graduate/Technical)    0.1060  0.3492   0.3036  0.7614  -0.5785  0.7905 \n                                                                       \nintrcpt                                                              . \nfactor(graderange)Grades K-5                                           \nfactor(graderange)Not Stated                                           \nfactor(graderange)Other (combined grades)                              \nfactor(graderange)Post-Secondary (Undergraduate/Graduate/Technical)    \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n#moderator test to get mean effect size for each group.\nmod.grade <- rma(yi, vi, mods = ~ factor(graderange)-1, data=dat1)\n#Display moderator result\nmod.gradeMixed-Effects Model (k = 27; tau^2 estimator: REML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.2302 (SE = 0.1006)\ntau (square root of estimated tau^2 value):             0.4798\nI^2 (residual heterogeneity / unaccounted variability): 72.28%\nH^2 (unaccounted variability / sampling variability):   3.61\n\nTest for Residual Heterogeneity:\nQE(df = 22) = 75.7955, p-val < .0001\n\nTest of Moderators (coefficients 1:5):\nQM(df = 5) = 34.6351, p-val < .0001\n\nModel Results:\n\n                                                                     estimate      se    zval    pval    ci.lb   ci.ub \nfactor(graderange)Grades 6-8                                           0.6096  0.3216  1.8956  0.0580  -0.0207  1.2400 \nfactor(graderange)Grades K-5                                           0.1960  0.3711  0.5282  0.5974  -0.5313  0.9234 \nfactor(graderange)Not Stated                                           0.0548  0.3949  0.1386  0.8897  -0.7193  0.8288 \nfactor(graderange)Other (combined grades)                              0.9911  0.5614  1.7654  0.0775  -0.1092  2.0914 \nfactor(graderange)Post-Secondary (Undergraduate/Graduate/Technical)    0.7157  0.1362  5.2561  <.0001   0.4488  0.9825 \n                                                                         \nfactor(graderange)Grades 6-8                                           . \nfactor(graderange)Grades K-5                                             \nfactor(graderange)Not Stated                                             \nfactor(graderange)Other (combined grades)                              . \nfactor(graderange)Post-Secondary (Undergraduate/Graduate/Technical)  *** \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"meta.html","id":"easily-create-tables","chapter":"10 Conventional Meta-Analysis","heading":"10.3.5.2 Easily Create Tables","text":"tried copy-paste results moderator analysis console word processing software yet? Go ahead try, book test .tried , looks terrible right? tables missing data reviewers want see, like number participants per level moderator. told Chris Palaguachi already spent time creating code create tables? Let’s take look code save hours hours calculations table manipulations.","code":""},{"path":"meta.html","id":"create-the-summary-table","chapter":"10 Conventional Meta-Analysis","heading":"10.3.5.2.1 Create the Summary Table","text":"First ’ll create summary table. way easier sounds.’s code ?First, ’re creating new data item, called mod.grade_table. coef(summary(mod.grade)) simply telling metafor want coefficient summary mod.grade data - called moderator analysis grade levels.Overall, basically saves data want separate table.now beautiful summary table. write spreadsheet now… number participants condition level moderator? number comparisons moderator? hand calculate … sounds boring takes long time. program analyses individually… also boring (’ve done want admit). , can use code Chris created automatically:","code":"\n#Only save table results \nmod.grade_table <-coef(summary(mod.grade))"},{"path":"meta.html","id":"calculating-participant-and-comparison-numbers-and-saving-the-table","chapter":"10 Conventional Meta-Analysis","heading":"10.3.5.2.2 Calculating Participant and Comparison Numbers, and Saving the Table","text":"First, ’ll compute number participants experimental control conditions level moderator. ’ll also calculate number comparisons level moderator. Finally, ’ll bind pre-existing table, write information table .csv file.’s code ?’s lot going code, ’ll look major pieces.First, create new data item called gradeSumParticipants. data counting number participants experimental control conditions, naming nexp nctrl, respectively.Next, new item called gradeNumComp. counting number comparisons item. create new data item (gradeNumComp) rename kcomparisons.Finally, create new table, bind data together, write csv file.great ? now almost data need moderator analysis. missing Qbetween value. Guess , script record . First, warning:IMPORTANT NOTE: code print Qbetween data twice. first presented : Qbetween (df) = #, p = #. second presented NA instead actual degrees freedom. want result degrees freedom, can ignore result NA printed.Example: .txt file contain : Qb( 4 ) = 4.28 , p = 0.369 Qb( NA ) = 4.28 , p = 0.369 first section, Qb( 4 ) = 4.28 , p = 0.369, proper information reporting result analysis.warning heeded, let’s take look code:’s code ?another complex code. First, extracting data moderator analysis (relevant Q statistics) naming something else.writing format want.write .txt file format used seeing Qbetween.Ok, now ’ve gotten moderator analyses run, information extracted. can simply replicate code, changing moderator names variable names required. also change name file written. like make moderator name minimize confusion later. recommend copy code variable, using find replace replace moderator names. ’s quite efficient!","code":"\n#calculate participants in each group and add it to the table, then save the table.\ngradeSumParticipants <- dat1 %>%\n  group_by(graderange) %>%\n  summarise(nexp = sum(intn, na.rm = TRUE),\n            nctrl = sum(cn, na.rm = TRUE))\ngradeNumComp <- dat1 %>%\n  count(graderange)\ngradeNumComp <- rename(gradeNumComp, kcomparisons = n)\ngrade_type_table.final<- cbind(gradeSumParticipants,gradeNumComp[c(2)], mod.grade_table) \nwrite.csv(grade_type_table.final, \"Mod.gradeResult.csv\")\n# Save QM Test and write it into a text file\nQgrade_collapsed_string <- paste(mod.gradeq[[\"QMdf\"]])\nQgrade_type1 <- data.frame(CollapsedQMdf = Qgrade_collapsed_string)\nQgrade_type2 <- round(mod.gradeq$QM,2)\nQgrade_type3 <- round(mod.gradeq$QMp,3)\n\nQgradeQ <- paste(\n  \"Qb(\",Qgrade_collapsed_string,\") =\", \n  Qgrade_type2,\n  \", p =\", \n  Qgrade_type3,\n  collapse = \" \"\n)\n\ncat(QgradeQ, \"\\n\")\ngradeQtest <- data.frame(Text = QgradeQ)\nwrite.table(gradeQtest, file = \"QgradeQ.txt\", row.names = FALSE, col.names = FALSE, quote = FALSE)"},{"path":"meta.html","id":"publication-bias","chapter":"10 Conventional Meta-Analysis","heading":"10.3.6 Publication Bias","text":"Oh ’re done yet, haven’t even talked publication bias yet! Don’t worry, pretty easy metafor, , great built functions.","code":""},{"path":"meta.html","id":"funnel-plot","chapter":"10 Conventional Meta-Analysis","heading":"10.3.6.1 Funnel Plot","text":"First ’ll create funnel plot check asymmetry.’s code ?code simply tells metafor create funnel plot overall meta-analysis result data.run code ’ll see following:","code":"\n#standard funnel plot\nfunnel(overallresult)"},{"path":"meta.html","id":"trim-and-fill-analysis","chapter":"10 Conventional Meta-Analysis","heading":"10.3.6.2 Trim and Fill Analysis","text":"Next ’ll check trim fill analysis see finds.’s code ?First creating new item, call ‘trimandfill’. use trimfill function data overall meta-analysis result.second line code simply displays results.Running code gives us following results console:’s result mean?first line tells us analysis indicates 2 studies may missing right side funnel. model results overall meta-analytic effect (accompanying data) two studies imputed.Let’s also check funnel plot look like add missing studies indicated trim fill analysis.’s code ?’re telling metafor use funnel function trimandfill data create funnel plot missing studies included.run code, see following chart plots:trim fill analysis, know two studies potentially missing right side funnel. also know included overall meta-analytic effect size g = .68. Recall overall meta-analytic model indicated effect size g = .61. case, studies absence notably change overall effect size, much issue. addition, missing studies included, effect size actually stronger one computed.","code":"\n# carry out trim-and-fill analysis\ntrimandfill <- trimfill(overallresult)\ntrimandfillEstimated number of missing studies on the right side: 2 (SE = 3.3967)\n\nRandom-Effects Model (k = 29; tau^2 estimator: REML)\n\ntau^2 (estimated amount of total heterogeneity): 0.2780 (SE = 0.1034)\ntau (square root of estimated tau^2 value):      0.5273\nI^2 (total heterogeneity / total variability):   75.67%\nH^2 (total variability / sampling variability):  4.11\n\nTest for Heterogeneity:\nQ(df = 28) = 103.1403, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.6774  0.1161  5.8323  <.0001  0.4497  0.9050  *** \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n# draw funnel plot with missing studies filled in\nfunnel(trimandfill)"},{"path":"meta.html","id":"eggers-regression","chapter":"10 Conventional Meta-Analysis","heading":"10.3.6.3 Egger’s Regression","text":"Another test can use Egger’s regression checks funnel plot asymmetry. ’s simple calculate, just use code :’s code ?runs Egger’s regression test using data overall meta-analysis result.Running code gives us result:’s result mean?want look p value. ’s less .05, know may significant funnel plot asymmetry.","code":"\n#Egger's regression\nregtest(overallresult)Regression Test for Funnel Plot Asymmetry\n\nModel:     mixed-effects meta-regression model\nPredictor: standard error\n\nTest for Funnel Plot Asymmetry: z = -0.0380, p = 0.9696\nLimit Estimate (as sei -> 0):   b =  0.6299 (CI: -0.2071, 1.4669)"},{"path":"meta.html","id":"fail-safe-n","chapter":"10 Conventional Meta-Analysis","heading":"10.3.6.4 Fail Safe N","text":"reviewers want see Fail Safe N tests. variants, ’ll focus Rosenthal’s Fail Safe N. common fail safe n test see reported literature. can use code calculate .’s code ?code telling metafor use fail safe n function (fsn), referencing effect size (yi) variance (vi) dat1 dataset (recall used calculate overall meta-analytic model).run code, get following result:’s result mean?tells us 1028 null effect (effect size 0) studies needed change p value overall meta-analytic effect size greater .05.Now, ’s important note approaches calculating fail safe n tests, Orwin’s Rosenberg’s. However, Rosenthal’s see commonly reported.","code":"\n#Rosenthal fail safe n\nfsn(yi, vi, data=dat1)Fail-safe N Calculation Using the Rosenthal Approach\n\nObserved Significance Level: <.0001\nTarget Significance Level:   0.05\n\nFail-safe N: 1028"},{"path":"meta.html","id":"reporting-publication-bias","chapter":"10 Conventional Meta-Analysis","heading":"10.3.6.5 Reporting Publication Bias","text":"Ok, ’ve now run variety tests check publication bias. tell us, report ? Well, know funnel plot reasonably symmetrical, trim fill found two missing studies change meta-analytic effect size much. Similarly, Egger’s regression indicate significant funnel plot asymmetry. Finally, Rosenthal’s fail safe n test said 1028 studies needed change overall meta-analytic effect size non-significant. Overall, can state publication bias likely significant concern analysis. can report specifically follows:checked presence publication bias using variety tests. First, constructed funnel plot. shown Figure 1, funnel plot reasonably symmetrical.Next conducted trim fill analysis check missing studies impact studies overall meta-analytic effect size. test found likely two studies missing right side funnel plot (Figure 2), change overall effect size g = .68, p < .001. notably different overall effect size calculated meta-analytic model (g = .61, p < .001).Next, used Egger’s regression test test funnel plot asymmetry, significant (z = -0.04, p = 0.97). Finally, used Rosenthal’s fail safe n test see many null effect studies needed change overall meta-analytic effect size non-significant. test showed 1028 studies needed.Based results four tests, publication bias expected significant influence results.","code":""},{"path":"meta.html","id":"thats-it","chapter":"10 Conventional Meta-Analysis","heading":"10.3.7 That’s it!","text":"’ve now gone steps needed conduct conventional meta-analysis. Congratulations! may seem intimidating, complete step, order, simple process. think - now ) code can use, slight modifications, every conventional meta-analysis conduct future, b) code can share friends, c) can share code publication others can replicate analysis. Just think - people done write book….","code":""},{"path":"meta.html","id":"section","chapter":"10 Conventional Meta-Analysis","heading":"10.3.7.1 ","text":"","code":""},{"path":"id_3LMA.html","id":"id_3LMA","chapter":"11 Three-Level Meta-Analysis","heading":"11 Three-Level Meta-Analysis","text":"chapter cover basics three-level meta-analysis R using metafor37. Remember conventional meta-analysis participant can counted ? Well, means exclude LOT data use conventional meta-analysis many education fields. can use three-level meta-analysis get around !Let’s look example: Say comparing impact learning virtual character game learning outcomes. study ’re coding two groups, virtual character group game group. immediate learning test, one week delayed learning test, month delayed learning test. test code? three-level meta-analysis, can code three! data lost, yay!noted conventional meta-analysis chapter, ’re focusing random-effects models . don’t know differences fixed random effects meta-analysis models, please see.38If aren’t familiar conventional meta-analysis, please read conducting meta-analysis. plenty free resources available. recommend starting great, free book, Meta-Analysis R39. book explains three-level meta-analysis quite well !Let’s say understand differences conventional three-level meta-analytic models, understand meta-analysis used , ’ve decided ’re moving ahead three-level model. Let’s explore R metafor using standardized mean differences effect size.","code":""},{"path":"id_3LMA.html","id":"preparing-your-data-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.1 Preparing your data","text":"Hopefully already run literature search, screened studies, extracted data. point forward assumes already completed steps.","code":""},{"path":"id_3LMA.html","id":"your-data-file-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.1.1 Your Data File","text":"Personally prefer use .csv files data file import R. ? ’s always used examples found online learning R, ’ve used ever since. change something works? Plus, .csv works many different software programs across various operating systems.  noted data extraction coding chapter, metafor uses two pieces information conducting meta-analysis need consider importing data R: effect size (yi) variance (vi). read previous chapters, know choices coding: can code mean, standard deviation, sample size experimental control groups use R metafor calculate effect size variance comparison (recommended method), can calculate effect size variance effect size . prefer former approach find helpful data check errors coding (misplaced decimal point – things happen!) also calculating sample sizes tables.choose use R metafor calculate effect sizes variance, important mean, standard deviation, sample size experimental group control group columns. recommend simple column titles descriptive easy remember, type R. See sample coding form use complete analysis. Note can many moderator variables wish, can continuous categorical.Important Reminder:Preparing data looks similar conventional meta-analysis. However, important two columns formatted specific way. First, need column simply labels comparison number duplicative comparison. words, can simply code data, create new column label respective comparison 1, 2, 3, 4, etc.Second study column. important every comparison study appears . avoid issues , recommend copy-pasting.end, coding form may look like , contains three effect sizes one study:, assuming done, let’s get onto fun stuff, running three-level meta-analysis!","code":""},{"path":"id_3LMA.html","id":"running-a-three-level-meta-analysis-in-metafor","chapter":"11 Three-Level Meta-Analysis","heading":"11.2 Running a Three-Level Meta-Analysis in Metafor","text":"","code":""},{"path":"id_3LMA.html","id":"example-data-for-this-analysis-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.2.1 Example Data for This Analysis","text":"want follow along specific example, ’ll want use subset data Schroeder et al.’s (2023)40 meta-analysis effects 360˚ video learning. data can downloaded .","code":""},{"path":"id_3LMA.html","id":"load-r-packages-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.2.2 Load R Packages","text":"First need load R packages. Hopefully installed already, won’t take long, just see R Basics chapter. Assuming already installed R packages, let’s load can analysis!’s code ?code simply loading metafor, ggplot2, dplyr packages R environment can analysis.","code":"\n###########################\n#Preparation#\n###########################\n\n#load packages\nlibrary(metafor)\nlibrary(ggplot2)\nlibrary(dplyr)"},{"path":"id_3LMA.html","id":"import-your-data-into-r-studio-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.2.3 Import Your Data Into R Studio","text":"first step conducting meta-analysis read data. , first want set working directory (R Basics chapter). ’ve set working directory saved sample data file , can use piece code.’s code ?see first piece code ‘df’, going name data file. <- indicates going name something. next piece telling R read .csv file working directory, can see file name used. basically, ’re saying import data call df.","code":"\n#name data file and read in .csv.\ndf <- read.csv(\"360 sample data.csv\")"},{"path":"id_3LMA.html","id":"calculating-effect-sizes-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.2.4 Calculating Effect Sizes","text":"Next, want calculate effect sizes variance effect size done already. can using code:’s code ?dat1 <- indicates naming new datafile ’re calling dat1.case ’re calculation. Escalc telling calculate effect size, measure=“SMD” saying want effect sizes standardized mean differences.next set variables (m1i, sd1i, n1i, m2i, sd2i, n2i) specific pieces information metafor needs calculate effect size. m1i mean intervention group. sd1i standard deviation intervention group. n1i sample size intervention group. m2i mean control group. sd2i standard deviation control group. n2i sample size control group. always found codes hard remember, coding form/data file use different column headings. can see tell metafor find variable using = sign. example, mean intervention group (m1i) called Exp_mean data file.Finally, need tell metafor find data, refer data already R. use datafile ‘df’.Now can make sure effect size variance effect size calculated:’s code ?display full data set saved ‘dat1’ console.However, find kind hard read lot data. , prefer write .csv file instead find easier read. code can :’s code ?write.csv tells R want create .csv file. saved working directory.dat1 telling R data want write .csv file.File = “ESdata.csv” simply naming datafile ” “. can name whatever want, example use ESdata file name.’re probably wondering, write .csv file effect size variance data saved R?Well, like look .csv file make sure don’t see effect sizes seem wrong. find easy track back study came can see made mistake coding. misplaced decimal point can huge implications analysis - step helps catch human errors.","code":"\ndat1 <- escalc(measure=\"SMD\", m1i=Exp_mean, sd1i=Exp_sd, n1i=Exp_n,\n               m2i=Ctrl_mean, sd2i=Ctrl_sd, n2i=Ctrl_n, data=df)\n#display dataset with ES and variance\ndat1\n#save .csv file with ES data. This goes into working directory\nwrite.csv(dat1, file = \"ESdata.csv\")"},{"path":"id_3LMA.html","id":"running-the-meta-analysis-model-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3 Running The Meta-Analysis Model","text":"Now part ’ve waiting , let’s run three-level meta-analysis model! can use code:’s code ?looks scary doesn’t ? ’s complicated actually. Let’s see ’re code.First, ’re naming meta-analysis result new piece data R, ’re naming ‘m_multi’rma.mv telling metafor want run random-effects, multivariate meta-analysis model. Within , ’re using yi reference effect size data within data set, vi reference effect size variance within data set.next line bit complex. Harrer et al. (2021)41 explain used define random effects nesting. Specifically, always start ~1 vertical bar three-level models. Next, need define grouping variables , case, ’s going studies (Study column data set), within studies effect size numbers (ES_number column data set).method specifying want use Restricted Maximum-Likelihood.test, default, uses z. However Harrer et al. (2021)42 recommend using ‘t’ similar Knapp-Hartung method.dfs = “contain” done using “residual” can lead inflated Type 1 error rate according Viechtbauer (n.d.)43.data = dat1 simply telling metafor data set within R reference running analysis.Finally, m_multi displays analysis results screen.","code":"\n#multilevel model\nm_multi <- rma.mv(yi,\n                  vi,\n                  random = ~ 1 | Study/ES_number,\n                  method = \"REML\",\n                  test = \"t\",\n                  dfs = \"contain\",\n                  data = dat1) \nm_multi"},{"path":"id_3LMA.html","id":"interpreting-the-results-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.1 Interpreting the Results","text":"run code, now see following:’s mean?Recall subset data Schroeder et al. (2023)44 numbers align published version.first line tells us multivariate random-effects model including 35 comparisons, tau2 estimated using restricted maximum likelihood estimation (REML).Next, see variance components. estimate tau2. first (sigma2.1) refers -study heterogeneity, whereas sigma2.2 refers within-comparison heterogeneity.Typically, important pieces interested reporting manuscript overall effect size, tau2, Q-test.effect size (model results output) interpreted standardized mean difference effect size, significant Q test indicates significant heterogeneity sample.Next, let’s check variance components depth.","code":"Multivariate Meta-Analysis Model (k = 35; method: REML)\n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed           factor \nsigma^2.1  2.6808  1.6373     12     no            Study \nsigma^2.2  0.1649  0.4061     35     no  Study/ES_number \n\nTest for Heterogeneity:\nQ(df = 34) = 285.5500, p-val < .0001\n\nModel Results:\n\nestimate      se     tval  df    pval    ci.lb   ci.ub    \n -0.3799  0.4843  -0.7843  11  0.4494  -1.4459  0.6861    \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"id_3LMA.html","id":"explaining-the-variance","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.2 Explaining the Variance","text":"step, saw tau2, see I2. ’re familiar conventional meta-analysis, know I2 tells us much variation explained -study heterogeneity. three-level meta-analysis can look find within-study -comparison value. Let’s check code:Important: First, actually need background work. Harrer et al. (2021)45 provided code helps us calculate I2,first need ‘teach’ R analysis., please visit link copy entire code: https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/mlm.variance.distribution.RGot code? Great, go ahead paste R console (results usually displayed R studio) hit enter. Awesome, now R knows analysis.Now can use code calculate I2.’s code ?creating new object, i2, using function var.comp overall meta-analysis model (m_multi).calculate summary statistics i2.finally display i2 screen.Let’s look results:’s result mean?run analysis, ’ll see 5.63% variance due level 2 (within-study) heterogeneity, 91.56% due -comparisons heterogeneity. Overall, model explains 97.2% variance.can also get information plot generated:Ok, ’ve established quite bit -comparison heterogeneity. consider tau2 -comparison heterogeneity notably higher within-study heterogeneity, results consistent help us rationalize conducting moderator analyses.","code":"\n#calculate i2 for each level\ni2 <- var.comp(m_multi)\nsummary(i2)\ni2$results\n        % of total variance    I2\nLevel 1            2.805362   ---\nLevel 2            5.631495  5.63\nLevel 3           91.563144 91.56\n\n$totalI2\n[1] 97.19464"},{"path":"id_3LMA.html","id":"checking-for-outliers-and-influence-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.3 Checking for Outliers and Influence","text":"point ’ve ran random-effects three-level meta-analysis model. also understand variance coming . However, checked outliers studies significant influence results. actually complex topic, many meta-analyses (January, 2024) education actually address ) searched outliers influence, b) metric used check outliers , c) outliers . Kind interesting right?’s can check outliers influence. Unfortunately isn’t quite easy evaluating outliers conventional meta-analysis, don’t worry, ’s difficult!First, let’s check outliers. ’re going slightly adapt Van Lissa’s (n.d.)46 method.’s code ?code identifies outliers using criteria individual effect size’s confidence interval overlap meta-analytical effect size confidence interval. creates nice chart ’ll see appear plots, create .csv file outliers indicated.Running code created plot, .csv file, displayed data console. prefer first examine plot, shows three outliers blue.can see three outliers using criteria, however don’t know comparisons . data console generated .csv file tell us comparisons outliers.point, similar conventional meta-analysis, need examine studies detail. First, check data entry errors. Sometimes decimal points wrong place, can easy create outlier.","code":"\n#adapting CI calculation and plotting from https://cjvanlissa.github.io/Doing-Meta-Analysis-in-R/detecting-outliers-influential-cases.html\n# Calculate CI for all observed effect sizes\ndat1$upperci <- dat1$yi + 1.96 * sqrt(dat1$vi)\ndat1$lowerci <- dat1$yi - 1.96 * sqrt(dat1$vi)\n# Create filter variable\ndat1$outlier <- dat1$upperci < m_multi$ci.lb | dat1$lowerci > m_multi$ci.ub\n# Count number of outliers:\nsum(dat1$outlier)\ndat1\n# Make a basic plot, based on the data in dat1, and specify that the x-variable is the effect size, 'd', the colour and fill of the histogram bars are based on\n# the value of 'outlier':\nggplot(data = dat1, aes(x = yi, colour = outlier, fill = outlier)) +\n  # Add a histogram with transparent bars (alpha = .2)\n  geom_histogram(alpha = .2) +\n  # Add a vertical line at the pooled effect value (m_re$b[1])\n  geom_vline(xintercept = m_multi$b[1]) +\n  # Apply a black and white theme\n  theme_bw()\n\n##Print file that lists outliers. This goes into working directory\nwrite.csv(dat1, file = \"outliers indicated.csv\")"},{"path":"id_3LMA.html","id":"checking-for-influence","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.3.1 Checking for Influence","text":"Assuming data entry errors, move check see outliers significant influence results. Similar conventional meta-analysis, ’re going examine Cook’s distance, dfbetas, hat values. can read influence diagnostics metrics used Viechtbauer Cheung (2010)47.Unfortunately, ’re using nice influence code provided asterisks influential studies, ’ll bit work .","code":""},{"path":"id_3LMA.html","id":"cooks-distance","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.3.1.1 Cook’s Distance","text":"First, let’s check Cook’s distance.’s code ?code calculates Cook’s distance based overall meta-analysis result (m_multi).Running code gives us following plot:, looking Cook’s distance 0.50 indicate study significant influence. shown, none outliers meet criteria.","code":"\n#cook's distance\ncooks <- cooks.distance(m_multi)\nplot(cooks, type=\"o\", pch=19, xlab=\"Observed Outcome\", ylab=\"Cook's Distance\")"},{"path":"id_3LMA.html","id":"dfbetas","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.3.1.2 dfbetas","text":"Now let’s check dfbetas. ’s code:’s code ?creating dfbetas item, using dfbetas function meta-analytic model (m_multi).display results console.gives us following results:’s result mean?, ’re looking values absolute value 1. exist (none data) know comparison significant influence results.","code":"\n#Calculate dfbetas\ndfbetas <-dfbetas(m_multi)\ndfbetas         intrcpt\n1  -0.626210184\n2   0.169860526\n3  -0.019773230\n4   0.018578841\n5   0.006064717\n6   0.005999710\n7  -0.089768522\n8   0.075905014\n9  -0.036595130\n10  0.032405437\n11  0.110392454\n12 -0.004587048\n13 -0.007298008\n14 -0.001561507\n15  0.021281904\n16 -0.044837905\n17 -0.019897092\n18  0.067207219\n19  0.003352683\n20  0.007897610\n21 -0.016373463\n22  0.002410328\n23  0.029562056\n24 -0.010640162\n25  0.009266463\n26  0.005062508\n27 -0.003420734\n28  0.015525088\n29 -0.007364825\n30  0.012981876\n31 -0.014656427\n32  0.012061267\n33 -0.011572638\n34 -0.001067083\n35  0.189468678"},{"path":"id_3LMA.html","id":"hat-values","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.3.1.3 Hat values","text":"Finally can check hat values help us check studies significant influence overall meta-analytical result. ’ll use code:’s code ?creating data item called hatvalues, calculating hat values using hatvalues function metafor overall meta-analytic model. display results console.Running code displays statistics console, honestly find challenging read format. instead, let’s write influence statistics .csv file easier viewing.’s code ?First, bind cooks distance, dfbetas, hatvalues data together one data set, name influence.write data .csv file saved working directory influenceinfo.csv., interpret hat values? little complex ’s like use .csv files. reminder, can read influence diagnostics metrics used Viechtbauer Cheung (2010)48. Specifically hatvalues, ’re looking values larger 3*(p/k), p number model coefficients k number cases49. like computation spreadsheet software, highlight cells exceed value.conversation , ’ll say find individual comparisons influential. ? outliers, none influential? Let’s explore .","code":"\n#calculate hatvalues\nhatvalues <- hatvalues(m_multi)\nhatvalues\n##Print file that lists influence info to examine them. This goes into working directory\ninfluence<-cbind(cooks, dfbetas, hatvalues)\nwrite.csv(influence, file = \"influenceinfo.csv\")"},{"path":"id_3LMA.html","id":"dealing-with-outliers-and-influential-studies","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.3.2 Dealing with Outliers and Influential Studies","text":"know data three comparisons dataset potential outliers, aren’t significant. ? Well, ’s lot options, recommended steps:Go back data check effect size. oddly large small? , check see typo data.Go back data check effect size. oddly large small? , check see typo data.Let’s say data errors. Next ’ll look study . something substantially methodologically ‘wrong’ significantly different studies sample? , may able rationalize removing study data set. , sure report removed study, , manuscript.Let’s say data errors. Next ’ll look study . something substantially methodologically ‘wrong’ significantly different studies sample? , may able rationalize removing study data set. , sure report removed study, , manuscript.Ok now things get real: Let’s say data good, study pretty well-done notably different studies sample. ? Well, ’s matter opinion.\ncurrent personal opinion retain study - valid data.\nAnother option “downsize” effect size slightly larger (smaller) next largest (smallest) effect size.\ndon’t prefer approach think valid data examined valid data, reasonable option. problem approach never seen metric much “larger” “smaller” change effect size . guess just… guess? seems imprecise since can/influence whole analysis, don’t like .\n\nfinal option remove outlier dataset.\ngenerally don’t like option rationalize study consistent rest analysis.\n\nOk now things get real: Let’s say data good, study pretty well-done notably different studies sample. ? Well, ’s matter opinion.current personal opinion retain study - valid data.current personal opinion retain study - valid data.Another option “downsize” effect size slightly larger (smaller) next largest (smallest) effect size.\ndon’t prefer approach think valid data examined valid data, reasonable option. problem approach never seen metric much “larger” “smaller” change effect size . guess just… guess? seems imprecise since can/influence whole analysis, don’t like .\nAnother option “downsize” effect size slightly larger (smaller) next largest (smallest) effect size.don’t prefer approach think valid data examined valid data, reasonable option. problem approach never seen metric much “larger” “smaller” change effect size . guess just… guess? seems imprecise since can/influence whole analysis, don’t like .final option remove outlier dataset.\ngenerally don’t like option rationalize study consistent rest analysis.\nfinal option remove outlier dataset.generally don’t like option rationalize study consistent rest analysis.purposes example, ’ll assume data good, nothing particularly notable study . Therefore retain effect size data.","code":""},{"path":"id_3LMA.html","id":"writing-up-the-results-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.4 Writing up the Results","text":"going write , may report something like :conducted random-effects three-level meta-analysis 35 comparisons extracted 12 studies. results indicated intervention significantly different control condition (g = -.38, p = .45). model indicates significantly heterogeneity within sample (Q(34) = 285.55, p < .001), tau2 = 2.68 (-comparisons) tau2 = .16 (within-studies). Furthermore, model explained 97.20% variance, 5.63% variance due within-study heterogeneity, 91.56% due -comparisons heterogeneity. detected three comparisons potential outliers, however examination studies indicate notable deviations studies sample. Furthermore, none potential outliers significantly influenced overall meta-analytical result. , potential outliers retained data analysis.","code":""},{"path":"id_3LMA.html","id":"moderator-analysis-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.5 Moderator Analysis","text":"’ve ran overall random-effects three-level meta-analysis model. people think important finding, education, think result generally kind interesting. really good stuff, opinion, examining potential moderator variables. Essentially, ’re going check see variables may influence overall effect size.might moderator variable? Well, depends field intervention ’re investigating. educational technologies, typically examine participant characteristics, study characteristics, intervention characteristics potential moderators.","code":""},{"path":"id_3LMA.html","id":"when-are-moderator-analyses-rationalized","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.5.1 When are moderator analyses rationalized?","text":"loaded question ! conventional meta-analysis, ’re looking overall Q statistics p value, well I2. ’re three-level meta-analysis., now let’s explore moderation analyses. ’re going focus categorical moderators plethora resources online run numerical moderators meta-regression.Important Note: Like conventional meta-analysis metafor, tricky thing categorical variable moderator analyses ’s actually two steps, look similar. Let’s take look different steps.","code":""},{"path":"id_3LMA.html","id":"calculate-qbetween-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.5.2 Calculate Qbetween","text":"First need calculate Qbetween. omnibus test tell us significant differences levels moderator. ’re going use grade range example:’s code ?first line first creating piece data R, ’re naming mod.gradeq (, stands moderator, grade, qbetween, can name whatever want).Next ’ll see familiar rma.mv code, new piece ‘mods = ~ factor(grade_c)’ piece. saying want run moderator analysis grade_c (’s column name data set) moderator.second line simply displays data screen.run code, ’re presented following:’s result mean?’s lot information want one thing: test moderators. case, ’s Test Moderators (coefficients 2:4): F(df1 = 3, df2 = 8) = 1.57, p-val = 0.27What ’re checking p value. can see test significant, means statistically significant moderator. words, example, effect intervention significantly different participants grades 9-12 participants post-secondary education.Qbetween value hand, now need create actual table ’ll report manuscript. ’ll note calculated Qbetween, one levels moderator missing, replaced term intercept. Well, ’s time fix get tables use reporting manuscript.’ll use similar code:’s code ?first line first creating piece data R, ’re naming mod.grade (, stands moderator, grade, can name whatever want). Next ’ll see familiar rma.mv code, ‘mods = ~ factor(grade_c)’ piece. saying want run moderator analysis grade_c (’s column name data set) moderator. ’s new -1, removes intercept runs ANOVA type model ’re used seeing categorical variables educational meta-analyses.second line simply displays data screen.run code, ’ll get results, look like :’s result mean?looks almost identical previous result calculated Qbetween. However, ’ll note intercept now gone. means, standard errors, p values, etc. levels moderator want report manuscript.Note test moderators different . Confusing right? Well, ’s two tests, named thing, testing different things. calculated Qbetween, test moderators testing significant differences levels moderator. However, test moderators testing moderators significantly different zero. totally different tests - use test moderator Qbetween value certainly !moderator variables test? Well, simply replace ‘grade_c’ variable whatever moderator variable column data labeled , don’t forget rename data items well (mod.gradeq mod.grade). can re-run two code sets calculate Qbetween effect sizes.","code":"\n####Grade Level  \n#calculate qb\nmod.gradeq <- rma.mv(yi,\n                     vi,\n                     data = dat1,\n                     random = ~ 1 | Study/ES_number, \n                     method = \"REML\",\n                     test = \"t\",\n                     dfs = \"contain\",\n                     mods = ~ factor(grade_c))\nsummary(mod.gradeq)Multivariate Meta-Analysis Model (k = 35; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n-39.0955   78.1911   90.1911   98.7950   93.6911   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed           factor \nsigma^2.1  2.9968  1.7311     12     no            Study \nsigma^2.2  0.1652  0.4064     35     no  Study/ES_number \n\nTest for Residual Heterogeneity:\nQE(df = 31) = 255.8519, p-val < .0001\n\nTest of Moderators (coefficients 2:4):\nF(df1 = 3, df2 = 8) = 1.5686, p-val = 0.2711\n\nModel Results:\n\n                            estimate      se     tval  df    pval    ci.lb   ci.ub    \nintrcpt                       0.2566  1.0087   0.2544   8  0.8056  -2.0695  2.5827    \nfactor(grade_c)Grades 9-12   -1.8710  1.2705  -1.4726  31  0.1509  -4.4623  0.7202    \nfactor(grade_c)University    -0.7356  1.1972  -0.6144  31  0.5434  -3.1773  1.7061    \nfactor(grade_c)Workforce      0.4138  2.0591   0.2010   8  0.8457  -4.3345  5.1621    \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n#calculate ES\nmod.grade <- rma.mv(yi,\n                    vi,\n                    data = dat1,\n                    random = ~ 1 | Study/ES_number, \n                    method = \"REML\",\n                    test = \"t\",\n                    dfs = \"contain\",\n                    mods = ~ factor(grade_c)-1)\nsummary(mod.grade)Multivariate Meta-Analysis Model (k = 35; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n-39.0955   78.1911   90.1911   98.7950   93.6911   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed           factor \nsigma^2.1  2.9968  1.7311     12     no            Study \nsigma^2.2  0.1652  0.4064     35     no  Study/ES_number \n\nTest for Residual Heterogeneity:\nQE(df = 31) = 255.8519, p-val < .0001\n\nTest of Moderators (coefficients 1:4):\nF(df1 = 4, df2 = 8) = 1.3172, p-val = 0.3420\n\nModel Results:\n\n                            estimate      se     tval  df    pval    ci.lb    ci.ub    \nfactor(grade_c)Grades 4-6     0.2566  1.0087   0.2544   8  0.8056  -2.0695   2.5827    \nfactor(grade_c)Grades 9-12   -1.6145  0.7725  -2.0899  31  0.0449  -3.1900  -0.0389  * \nfactor(grade_c)University    -0.4790  0.6448  -0.7429  31  0.4631  -1.7941   0.8360    \nfactor(grade_c)Workforce      0.6704  1.7951   0.3734   8  0.7185  -3.4691   4.8099    \n\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"},{"path":"id_3LMA.html","id":"easily-create-tables-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.5.3 Easily Create Tables","text":"tried copy-paste results moderator analysis console word processing software yet? Go ahead try, book test .tried , looks terrible right? tables missing data reviewers want see, like number participants per level moderator. told Chris Palaguachi already spent time creating code create tables? Let’s take look code save hours hours calculations table manipulations.","code":""},{"path":"id_3LMA.html","id":"create-the-summary-table-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.5.3.1 Create the Summary Table","text":"First ’ll create summary table. way easier sounds.’s code ?First, ’re creating new data item, called mod.grade_table. coef(summary(mod.grade)) simply telling metafor want coefficient summary mod.grade data - called moderator analysis grade levels.Overall, basically saves data want separate table.now beautiful summary table. write spreadsheet now… number participants condition level moderator? number comparisons moderator? hand calculate … sounds boring. program analyses individually… also boring (’ve done want admit). , can use code Chris created automatically:","code":"\n#Only save table results for word \nmod.grade_table <-coef(summary(mod.grade))"},{"path":"id_3LMA.html","id":"calculating-participant-and-comparison-numbers-and-saving-the-table-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.3.5.3.2 Calculating Participant and Comparison Numbers, and Saving the Table","text":"First, ’ll compute number participants experimental control conditions level moderator. ’ll also calculate number comparisons level moderator. Finally, ’ll bind pre-existing table, write information table .csv file.’s code ?’s lot going code, ’ll look major pieces.First, create new data item called gradeSumParticipants. data counting number participants experimental control conditions, naming nexp nctrl, respectively.Next, new item called gradeNumComp. counting number comparisons item. create new data item (gradeNumComp) rename kcomparisons.Finally, create new table, bind data together, write csv file.great ? now almost data need moderator analysis. missing piece Qbetween value. Guess , script record .’s code ?another complex code. First, extracting data moderator analysis (relevant Q statistics) naming something else.writing format want.write .txt file format used seeing Qbetween.Ok, now ’ve gotten moderator analyses run information extracted. can simply replicate code, changing moderator names variable names required. also change name file written. like make moderator name minimize confusion later. recommend copy code variable, using find replace replace moderator names. ’s quite efficient!","code":"\n#calculate participants in each group and add it to the table\nmod.gradeSumParticipants <- dat1 %>%\n  group_by(grade_c) %>%\n  summarise(nexp = sum(Exp_n, na.rm = TRUE),\n            nctrl = sum(Ctrl_n, na.rm = TRUE))\nmod.gradeNumComp <- dat1 %>%\n  count(grade_c)\nmod.gradeNumComp <- rename(mod.gradeNumComp, kcomparisons = n)\nmod.grade_table.final<- cbind(mod.gradeSumParticipants,mod.gradeNumComp[c(2)], mod.grade_table) \nwrite.csv(mod.grade_table.final, \"mod.gradeResult.csv\")\n# Save QM Test and write it into a text file\nQmod.grade_collapsed_string <- paste(mod.gradeq[[\"QMdf\"]], collapse = \", \")\nQmod.grade1 <- data.frame(CollapsedQMdf = Qmod.grade_collapsed_string)\nQmod.grade2 <- round(mod.gradeq$QM,2)\nQmod.grade3 <- round(mod.gradeq$QMp,3)\n\nQmod.gradeQ <- paste(\n  \"Qb(\",Qmod.grade_collapsed_string,\") =\", \n  Qmod.grade2,\n  \", p =\", \n  Qmod.grade3,\n  collapse = \" \"\n)\n\ncat(Qmod.gradeQ, \"\\n\")\nmod.gradeQtest <- data.frame(Text = Qmod.gradeQ)\nwrite.table(mod.gradeQtest, file = \"Qmod.gradeQ.txt\", row.names = FALSE, col.names = FALSE, quote = FALSE)"},{"path":"id_3LMA.html","id":"plots","chapter":"11 Three-Level Meta-Analysis","heading":"11.4 Plots","text":"always include forest plot results. Unfortunately, bit complex three-level meta-analysis study-level effects (often) multiple comparisons within study. However, really fun visualizations can create borrow code others. Let’s see ’s possible.Important Note: ’re going use different file creating forest caterpillar plots. file data preparation needed create funnel plots evaluate publication bias. reason, tend create forest plots, caterpillar plots, funnel plots time. addition, uses different data file, generally create second R code file well specifically making plots. ’s grouped end chapter.\ncode plots section adapted Fernández-Castilla et al. (2020)50. slightly adapted code fit data.","code":""},{"path":"id_3LMA.html","id":"preparatory-work","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.0.1 Preparatory Work","text":"dig ‘-’ creating forest plots three-level meta-analysis, need create new data file raw data compute couple new statistics. let’s first.’ll need .csv file contains columns outcome number (just sequential, meaning 1 n number comparisons). Next, need study column, number studies (comparisons, studies). need author names wish see plots. Next effect size, variance, standard error.mean practically? Well, , usually means copy-paste author list data sheet, well effect size variance.leaves one tricky variable… standard error. don’t data set currently. remember relationships standard error, participant numbers, variance? basic statistics stuff right?Don’t worry, didn’t remember either. standard error computed dividing standard deviation square root sample size.recall, already sample sizes coded. copy-paste experimental control group participant numbers, sum comparison.Now just need calculate standard deviation. Well, standard deviation squareroot variance, know variance. ’s easy compute spreadsheet.Together, data points let us compute standard error spreadsheet.end, spreadsheet look like one, ’ll use creating plots.Now, let’s get R code load dataWhat’s code ?First, load packages.Next, import data working directory. call file “data plots” ’m really creative.Next naming bunch vectors ’ll need create plots publication bias plots.","code":"\n#load packages\nlibrary(ggplot2)\nlibrary(plyr)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(metafor)\nlibrary(metaSEM)\nlibrary(ggrepel)\n\n#load data\nmydf<-read.csv(\"data for plots.csv\")\n\n\nstudy<-mydf$study\nout<-mydf$outcome\nES<-mydf$effect_size\nvar<-mydf$variance\nse<-mydf$standard_error\nauthor<-mydf$author"},{"path":"id_3LMA.html","id":"three-level-meta-analysis-forest-plot","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.0.2 Three-Level Meta-Analysis Forest Plot","text":"Let’s create three-level forest plot:’s code ?Well, lot going , understand . ’re making beautiful three-level meta-analysis funnel plot seen .code works correctly , forest plot appear plots section R studio.Absolutely beautiful plot right? can read different items colors mean Fernández-Castilla et al. (2020)51. Remember, code plots chapter paper. quickly explain major points, black boxes represent average effect size comparisons within study, black lines study precision. grey lines median precision one effect size study. size effect size box representative weight analysis. J represents many comparisons analyzed study.","code":"\nforest_plot_3<-function(author, study, ES, out, var, se, size_lines){\n  size_lines=size_lines\n  dataset<-data.frame(study,author, ES, out, var, se)\n  row = 1\n  nrow=max(dataset$study)\n  studyn=max(dataset$study)\n  studyinfo = data.frame(Study = numeric(nrow),\n                         author = numeric(nrow),\n                         id = numeric(nrow),\n                         ES= numeric(nrow),\n                         SE= numeric(nrow),\n                         Var=numeric(nrow),\n                         cilb= numeric(nrow),\n                         ciub= numeric(nrow),\n                         k= numeric(nrow),\n                         out=numeric(nrow),\n                         median_Var=numeric(nrow),\n                         S_cilb=numeric(nrow),\n                         S_ciub=numeric(nrow),\n                         Weight=numeric(nrow))\n  Study1 =c()\n  Study2 =c()\n  dataset$author<-as.character(dataset$author)\n  meta_abu <- summary(meta3(y=ES, v=var, cluster=study, data=dataset))\n  estimate<-round(meta_abu$coefficients$Estimate[1], digits=2)\n  tau<-meta_abu$coefficients$Estimate[3]\n  out<-meta_abu$coefficients$Estimate[2]\n  \n  \n  \n  for (i in 1:max(dataset$study)){\n    data<-subset(dataset, study==i)\n    uni=nrow(data)\n    \n    if (uni==1) {\n      studyinfo$ES[row]<-data$ES\n      studyinfo$SE[row]<-data$se\n      studyinfo$cilb[row]<-(data$ES-(data$se*1.96))\n      studyinfo$ciub[row]<-(data$ES+(data$se*1.96))\n      studyinfo$S_cilb[row]<-(data$ES-(data$se*1.96))\n      studyinfo$S_ciub[row]<-(data$ES+(data$se*1.96))\n      studyinfo$Weight[row]<-1/ (data$se^2)\n    }\n    else {\n      a<-rma(y=data$ES, vi=data$var, data=data, method=\"REML\")\n      \n      diagonal<-1/(data$var+out)\n      D<-diag(diagonal)\n      obs<-nrow(data)\n      I<-matrix(c(rep(1,(obs^2))),nrow=obs)\n      M<-D%*%I%*%D\n      inv_sumVar<-sum(1/(data$var+out))\n      O<-1/((1/tau)+inv_sumVar)\n      V<-D-(O*M)\n      T<-as.matrix(data$ES)\n      X<-matrix(c(rep(1,obs)), ncol=1)\n      var_effect<-solve(t(X)%*%V%*%X)\n      \n      studyinfo$ES[row]<-a$b\n      studyinfo$SE[row]<-a$se\n      studyinfo$cilb[row]<-a$ci.lb\n      studyinfo$ciub[row]<-a$ci.ub\n      studyinfo$S_cilb[row]<-a$b - 1.96*median(data$se)\n      studyinfo$S_ciub[row]<-a$b + 1.96*median(data$se)\n      studyinfo$Weight[row]<-1/ var_effect\n    }\n    \n    studyinfo$Study[row]<-c(Study1,paste(\"Study\",i))\n    studyinfo$id[row]<-i\n    studyinfo$k[row]<-nrow(data)\n    studyinfo$author[row]<-data$author[1]\n    studyinfo$out[row] <- c(Study2, paste(\"J =\",studyinfo$k[i]))\n    studyinfo$median_Var[row]<-median(data$var)\n    studyinfo$Var<-(studyinfo$SE)^2\n    row = row + 1      \n  }\n  \n  \n  minimum<-min(studyinfo$S_cilb)\n  maximum<-max(studyinfo$S_ciub)\n  lim_minimum<-minimum-0.10\n  lim_maximum<-maximum+0.25\n  r_lim_minimum<-round(lim_minimum, digits=0)\n  r_lim_maximum<-round(lim_maximum, digits=0)\n  abs_r_lim_minimum<-abs(r_lim_minimum)\n  abs_r_lim_maximum<-abs(r_lim_maximum)\n  dec_min<-round(abs((lim_minimum-r_lim_minimum)*100), digits=0)\n  dec_max<-round(abs((lim_maximum-r_lim_maximum)*100), digits=0)\n  \n  if (dec_min < 25) {\n    c=25/100\n  } else if (dec_min>25 & dec_min<50) {\n    c=50/100\n  } else if (dec_min>50 & dec_min<75) {\n    c=75/100\n  } else {\n    c=abs_r_lim_minimum+1\n  }\n  \n  if (dec_max < 25) {\n    d=25/100\n  } else if (dec_max>25 & dec_max<50) {\n    d=50/100\n  } else if (dec_max>50 & dec_max<75) {\n    d=75/100\n  } else {\n    d=abs_r_lim_maximum+1\n  }\n  \n  lim_minimum<-r_lim_minimum-c\n  lim_maximum<-r_lim_maximum+d\n  \n  Axis_ES <- seq(lim_minimum, lim_maximum, by=0.50)\n  Axis_ES<-Axis_ES[order(Axis_ES)]\n  empty <- data.frame(id=c(NA,NA), ES=c(NA, NA), cilb=c(NA, NA),ciub=c(NA,NA),\n                      k=c(NA,NA), Study=c(NA,NA), SE=c(NA, NA), \n                      out=c(NA,NA),median_Var=c(NA,NA), S_cilb=c(NA,NA), S_ciub=c(NA,NA),\n                      Var=c(NA, NA), Weight=c(NA,NA), author=c(\"\",\"Summary\"))\n  \n  studyinfo <- rbind(studyinfo, empty)\n  studyinfo$Study=factor(studyinfo$Study ,levels=unique(studyinfo$Study))\n  studyinfo$author=factor(studyinfo$author ,levels=unique(studyinfo$author))\n  r_diam<-studyn-2\n  sum.y <- c(1, 0.7, 1, 1.3, rep(NA,r_diam )) \n  sum.x <- c(meta_abu$coefficients$lbound[1], meta_abu$coefficients$Estimate[1], meta_abu$coefficients$ubound[1], meta_abu$coefficients$Estimate[1], rep(NA, r_diam))\n  studyinfo<-data.frame(studyinfo, sum.x, sum.y )\n  studyinfo<-studyinfo[, c(15,16,3,4,5,6,7,8,9,10,11,12,13,14,1,2)]\n  \n  forest<-ggplot()+ geom_point(data=studyinfo, aes(y=factor(author), x = ES, xmin =cilb, xmax = ciub, size=Weight), shape=15) +\n    #scale_size_area()+\n    geom_errorbarh(data=studyinfo, aes(y=factor(author), x = ES, xmin =cilb, xmax = ciub), size=1, height=.2)+\n    scale_x_continuous(limits=c(lim_minimum,lim_maximum),breaks=Axis_ES)+ \n    scale_y_discrete(limits=rev(levels(studyinfo$author)))+\n    geom_vline(xintercept=0)+\n    theme(panel.grid.major = element_blank(),\n          panel.grid.minor = element_blank(),\n          legend.position=\"none\",\n          panel.background = element_blank(),\n          axis.line.x = element_line(colour = \"black\"),\n          axis.ticks.y =element_blank(),\n          axis.title.x=element_text(size=10, color =\"black\",family=\"sans\"),\n          axis.title.y=element_blank(),\n          axis.text.y = element_text(family=\"sans\",size=10, color = \"black\",hjust=0, angle=0),\n          axis.text.x = element_text(size=10, color=\"black\",family=\"sans\"), \n          axis.line.y =element_blank())+\n    labs(x = paste(\"Pooled Effect Size\", estimate), hjust=-2)+\n    geom_polygon(aes(x=sum.x, y=sum.y))+\n    geom_vline(xintercept=estimate, colour=\"black\",linetype=4)+\n    geom_text(aes(x=lim_maximum, y=factor(studyinfo$author),label = studyinfo$out), size=3)\n \n  if (size_lines==1){\n   \n  forest<-forest+geom_point(data=studyinfo, aes(y=factor(author), x=ES, xmin = S_cilb, xmax =  S_ciub), shape=15)+\n    geom_errorbarh(data=studyinfo, aes(y=factor(author), x=ES, xmin = S_cilb, xmax =  S_ciub, size=k), width=.8,  height=.4, alpha=.2) #Cambiar .3 por .8\n  } else{\n    \n    forest<-forest+geom_point(data=studyinfo, aes(y=factor(author), x=ES, xmin = S_cilb, xmax =  S_ciub), shape=15)+\n      geom_errorbarh(data=studyinfo, aes(y=factor(author), x=ES, xmin = S_cilb, xmax =  S_ciub), width=.8,  height=.4, alpha=.5) #Cambiar .3 por .8\n    \n  }\n  print(forest)\n\n}\n\n\n##If we want the size of the grey lines to be proportional to the number of outcomes within each study, then size_lines=1\n##otherwise, specify that size_lines=0\n\nforest_plot_3(author, study, ES, out, var, se, size_lines=1)"},{"path":"id_3LMA.html","id":"caterpillar-plots","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.0.3 Caterpillar Plots","text":"forest plots great, sometimes want different way visualize data. Caterpillar plots interesting way visualize data. , borrow code Fernández-Castilla et al. (2020)52.","code":""},{"path":"id_3LMA.html","id":"all-comparisons","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.0.3.1 All Comparisons","text":"First, let’s look comparisons one plot:’s code ?code creates caterpillar plot comparisons analysis.create plot like :can see, 35 comparisons included plot, listed smallest (left) largest (right). red line overall meta-analytic effect size.","code":"\nCaterpillar<-function(study, ES, out, var, se){ \n  dataset<-data.frame(study, ES, out, var, se)\n  dataset$cilb<-dataset$ES-(1.96*dataset$se)\n  dataset$ciub<-dataset$ES+(1.96*dataset$se)\nmeta_abu <- summary(meta3(y=ES, v=var, cluster=study, data=dataset))\ndataset<-dataset[order(dataset$ES),]\ndataset$id<-c(rep(1:length(dataset$se)))\nP_combined<-nrow(dataset)+10\ncombined_ES<-data.frame(ES=meta_abu$coefficients$Estimate[1],\n                        cilb=meta_abu$coefficients$lbound[1], ciub=meta_abu$coefficients$ubound[1],\n                        id=P_combined)\n\n\nminimum<-min(dataset$cilb)\nmaximum<-max(dataset$ciub)\nlim_minimum<-minimum-0.10\nlim_maximum<-maximum+0.10\nr_lim_minimum<-round(lim_minimum, digits=0)\nr_lim_maximum<-round(lim_maximum, digits=0)\nabs_r_lim_minimum<-abs(r_lim_minimum)\nabs_r_lim_maximum<-abs(r_lim_maximum)\ndec_min<-round(abs((lim_minimum-r_lim_minimum)*100), digits=0)\ndec_max<-round(abs((lim_maximum-r_lim_maximum)*100), digits=0)\n\nif (dec_min < 25) {\n  c=25/100\n} else if (dec_min>25 & dec_min<50) {\n  c=50/100\n} else if (dec_min>50 & dec_min<75) {\n  c=75/100\n} else {\n  c=abs_r_lim_minimum+1\n}\n\nif (dec_max < 25) {\n  d=25/100\n} else if (dec_max>25 & dec_max<50) {\n  d=50/100\n} else if (dec_max>50 & dec_max<75) {\n  d=75/100\n} else {\n  d=abs_r_lim_maximum+1\n}\n\nlim_minimum<-r_lim_minimum-c\nlim_maximum<-r_lim_maximum+d\n\nAxis_ES <- seq(lim_minimum, lim_maximum, by=2)\n#Axis_ES<- c(Axis_ES,0)\nAxis_ES<-Axis_ES[order(Axis_ES)]\n\np <- ggplot()+\n  geom_point(data=dataset, aes(y=id, x=ES),colour = \"black\")+\n  geom_errorbarh(data=dataset, aes(y=id, x=ES, xmin = cilb, xmax = ciub),size=1,  height=.2)+\n  scale_x_continuous(limits=c(lim_minimum,lim_maximum),breaks=Axis_ES)+ \n  geom_vline(xintercept=0,size=1.2, alpha=0.7,colour=\"#EF3B2C\", linetype=\"twodash\")\np<-p+\n  geom_point(data=combined_ES, aes(y=id, x=ES), colour = \"red\", size=2)+\n  geom_errorbarh(data=combined_ES, aes(y=id, x=ES, xmin = cilb, xmax = ciub), colour=\"red\", size=1,  height=.2)+\n  coord_flip()+\n  theme( axis.line=element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n         legend.position=\"none\",panel.background = element_blank(), axis.line.x = element_blank(), axis.line.y = element_line(colour = \"black\"),\n         axis.title.x=element_blank(), axis.title.y=element_text(size=14), axis.text.y = element_text(size=12, color=\"black\"), axis.text.x = element_blank(), axis.ticks = element_blank())+\n  xlab(\"Effect sizes\")\n\nprint(p)\n\n}\nCaterpillar(study, ES, out, var, se)"},{"path":"id_3LMA.html","id":"study-level-plot","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.0.3.2 Study-Level Plot","text":"prefer plot study-level results, similar forest plot, can use code, Fernández-Castilla et al. (2020)53:’s code ?code creates caterpillar plot study-level effects rather comparison-level.produce plot:Caterpillar plots , January 2024, common educational literature. However, see value including visualization publications.","code":"\n\ncaterpillar_studies<-function(study, ES, out, var, se){\ndataset<-data.frame(study, ES, out, var, se)\n  meta_abu <- summary(meta3(y=ES, v=var, cluster=study, data=dataset))\n  row = 1\n  nrow=max(dataset$study)\n  studyn=max(dataset$study)\n  studyinfo = data.frame(Study = numeric(nrow),\n                         ES= numeric(nrow),\n                         SE= numeric(nrow),\n                         cilb= numeric(nrow),\n                         ciub= numeric(nrow),\n                         S_cilb=numeric(nrow),\n                         S_ciub=numeric(nrow))\n  Study1 =c()\n  Study2 =c()\n  \n  for (i in 1:max(dataset$study)){\n    data<-subset(dataset, study==i)\n    uni=nrow(data)\n    if (uni==1) {\n      studyinfo$ES[row]<-data$ES\n      studyinfo$SE[row]<-data$se\n      studyinfo$cilb[row]<-(data$ES-(data$se*1.96))\n      studyinfo$ciub[row]<-(data$ES+(data$se*1.96))\n      studyinfo$S_cilb[row]<-(data$ES-(data$se*1.96))\n      studyinfo$S_ciub[row]<-(data$ES+(data$se*1.96)) \n    }\n    \n    else {\n    a<-rma(y=data$ES, vi=data$var, data=data, method=\"REML\")\n    studyinfo$ES[row]<-a$b\n    studyinfo$SE[row]<-a$se\n    studyinfo$cilb[row]<-a$ci.lb\n    studyinfo$ciub[row]<-a$ci.ub\n    studyinfo$S_cilb[row]<-a$b - 1.96*median(data$se)\n    studyinfo$S_ciub[row]<-a$b + 1.96*median(data$se)\n    }\n    studyinfo$Study[row]<-c(Study1,paste(\"Study\",i))\n    row = row + 1      \n    \n  }\n  \n  studyinfo<- studyinfo[order(studyinfo$ES),]\n  studyinfo$id<-c(rep(1:length(studyinfo$ES)))\n  \n  P_combined<-nrow(studyinfo)+2\n  combined_ES<-data.frame(ES=meta_abu$coefficients$Estimate[1],\n                          cilb=meta_abu$coefficients$lbound[1], ciub=meta_abu$coefficients$ubound[1],\n                          id=P_combined)\n  \n  \n  minimum<-min(studyinfo$S_cilb)\n  maximum<-max(studyinfo$S_ciub)\n  lim_minimum<-minimum-0.10\n  lim_maximum<-maximum+0.10\n  r_lim_minimum<-round(lim_minimum, digits=0)\n  r_lim_maximum<-round(lim_maximum, digits=0)\n  abs_r_lim_minimum<-abs(r_lim_minimum)\n  abs_r_lim_maximum<-abs(r_lim_maximum)\n  dec_min<-round(abs((lim_minimum-r_lim_minimum)*100), digits=0)\n  dec_max<-round(abs((lim_maximum-r_lim_maximum)*100), digits=0)\n  \n  if (dec_min < 25) {\n    c=25/100\n  } else if (dec_min>25 & dec_min<50) {\n    c=50/100\n  } else if (dec_min>50 & dec_min<75) {\n    c=75/100\n  } else {\n    c=abs_r_lim_minimum+1\n  }\n  \n  if (dec_max < 25) {\n    d=25/100\n  } else if (dec_max>25 & dec_max<50) {\n    d=50/100\n  } else if (dec_max>50 & dec_max<75) {\n    d=75/100\n  } else {\n    d=abs_r_lim_maximum+1\n  }\n  \n  lim_minimum<-r_lim_minimum-c\n  lim_maximum<-r_lim_maximum+d\n  \n  Axis_ES <- seq(lim_minimum, lim_maximum, by=0.50)\n  Axis_ES<- c(Axis_ES,0)\n  Axis_ES<-Axis_ES[order(Axis_ES)]\n  \n  \n  r <- ggplot()+\n    geom_point(data=studyinfo, aes(y=id, x=ES),colour = \"black\")+\n    geom_errorbarh(data=studyinfo, aes(y=id, x=ES, xmin = cilb, xmax = ciub),  size=1, height=.2)+\n    scale_x_continuous(limits=c(lim_minimum,lim_maximum),breaks=Axis_ES)+ \n    geom_vline(xintercept=0,size=1.2, alpha=0.7,colour=\"#EF3B2C\", linetype=\"twodash\")\n  \n  r<-r + geom_point(data=studyinfo, aes(y=id, x=ES),colour = \"black\")+\n    geom_errorbarh(data=studyinfo, aes(y=id, x=ES, xmin = S_cilb, xmax =  S_ciub),width=.2,  height=.2, alpha=.5)+\n    geom_point(data=combined_ES, aes(y=id, x=ES),colour = \"red\", size=2)+\n    geom_errorbarh(data=combined_ES, aes(y=id, x=ES, xmin = cilb, xmax =ciub),height=.2, colour = \"red\")+\n    coord_flip()+\n    theme(axis.line=element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n          legend.position=\"none\",panel.background = element_blank(), axis.line.x = element_blank(), axis.line.y = element_line(colour = \"black\"),\n          axis.title.x=element_blank(), axis.title.y=element_text(size=14), axis.text.y = element_text(size=12, color=\"black\"), axis.text.x = element_blank(), axis.ticks = element_blank())+\n    xlab(\"Meta-analytic study means\")\n  \n print(r)\n}\n\ncaterpillar_studies(study, ES, out, var, se)"},{"path":"id_3LMA.html","id":"publication-bias-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.1 Publication Bias","text":"Oh ’re done yet, haven’t even talked publication bias yet! Publication bias difficult examine three-level models conventional meta-analysis models. Furthermore, tests conventional meta-analysis models often don’t function well three-level applications (Rodgers & Pustejovsky, 2021)54. Instead, can look funnel plots examine asymmetry.","code":""},{"path":"id_3LMA.html","id":"funnel-plots","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.1.1 Funnel Plots","text":", ’re going borrow methods adapt code Fernández-Castilla et al. (2020)55.First ’ll create funnel plot effect sizes check asymmetry.’s code ?code creates funnel plot effect sizes.run code ’ll see following:overall effect size grey vertical line left zero. want see symmetry around line, vertically horizontally. don’t. looks pretty asymmetrical doesn’t ?Now let’s create funnel plot study-level effects, help Fernández-Castilla et al.’s (2020)56 code:’s code ?code creates funnel plot study-level effects.code creates following plot:, overall effect size vertical line left zero. want see symmetry around line, vertically horizontally. , don’t. Interesting!","code":"\nthree_funnel<-function(study, ES, out, var, se){\n  \ndataset<-data.frame(study, ES, out, var, se)\ncontour.points=200\nmeta_abu <- summary(meta3(y=ES, v=var, cluster=study, data=dataset))\nestimate<-meta_abu$coefficients$Estimate[1]\ntau<-meta_abu$coefficients$Estimate[3]\nout<-meta_abu$coefficients$Estimate[2]\n\nmaxse<-max(dataset$se)\nylim<-c(0, maxse)\ncsize <- seq(ylim[1], ylim[2], length.out = contour.points)\ncsize[csize <= 0] <- 1e-07 * min(dataset$se)\ncsize\n\nCI_Lim<-matrix(0, nrow=length(csize), ncol=2)\ncolnames(CI_Lim)<-c(\"lb_total\", \"ub_total\")\n\nfor (i in 1:length(csize)){\n  CI_Lim[i,1]<-estimate-1.96*sqrt((csize[i]^2)+tau+out) #add 1.96*\n  CI_Lim[i,2]<-estimate+1.96*sqrt((csize[i]^2)+tau+out)\n}\nCI_Lim<-as.data.frame(CI_Lim)\n\ndataset$study<-as.character(dataset$study)\ndataset$study <- factor(dataset$study)\ngeom.text.size = 3\nmax_SE<-max(dataset$se)\nle<-length(CI_Lim[,1])\n\nif ((CI_Lim[le,1])< 0) {\n  minimum=min(CI_Lim[,1])\n} else {\n  minimum=max(CI_Lim[,1])\n} \n\nif ((CI_Lim[le,2]) > 0) {\n  maximum=max(CI_Lim[,2])\n} else {\n  maximum=min(CI_Lim[,2])\n} \n\n\nlim_minimum<-floor(minimum-0.10)\nlim_maximum<-ceiling(maximum+0.10)\nAxis_ES <- seq(lim_minimum, lim_maximum, by=1)\n\nd <- ggplot(data=dataset, aes(x = se, y = ES, ylim(0,max_SE)))+\n  geom_point()+\n  xlab('Standard Error')+ \n  ylab('Effect size: g')+\n  geom_hline(yintercept= estimate)+\n  geom_hline(yintercept= 0, color='grey')+\n  scale_x_reverse()+\n  scale_y_continuous(breaks=Axis_ES, limits =c(lim_minimum,lim_maximum))+\n  coord_flip()+\n  theme(panel.grid.major=element_blank(),\n        panel.grid.minor=element_blank(),\n        panel.border=element_blank(),\n        panel.background = element_blank(),\n        axis.line=element_line(),\n        axis.title = element_text(size=14),\n        axis.text = element_text(size=12, color=\"black\"),\n        text=element_text())\n\nd <- d + geom_line(data=CI_Lim, aes(y=lb_total, x=csize), colour=\"black\")+\n  geom_line(data=CI_Lim, aes(y=ub_total, x=csize), colour=\"black\")\nprint(d)\n}\n\nthree_funnel(study, ES, out, var, se)\nthree_funnel_study<-function(study, ES, out, var, se, size_dots, numbers){\n numbers=numbers\n   size_dots=size_dots\n  dataset<-data.frame(study, ES, out, var, se)\n  contour.points=200\n  \n  meta_abu <- summary(meta3(y=ES, v=var, cluster=study, data=dataset))\n  estimate<-meta_abu$coefficients$Estimate[1]\n  tau<-meta_abu$coefficients$Estimate[3]\n  out<-meta_abu$coefficients$Estimate[2]\n\n  row = 1\n  nrow=max(dataset$study)\n  studyinfo = data.frame(Study = numeric(nrow),\n                         id = numeric(nrow),\n                         ES= numeric(nrow),\n                         SE= numeric(nrow),\n                         k= numeric(nrow),\n                         median_SE=numeric(nrow))\n  Study1 =c()\n  geom.text.size = 3\n  \n  for (i in 1:max(dataset$study)){\n    data<-subset(dataset, study==i)\n    uni=nrow(data)\n    \n    if (uni==1) {\n      studyinfo$ES[row]<-data$ES\n      studyinfo$SE[row]<-data$se\n      studyinfo$median_SE[row]<-data$se\n    }\n    \n    else {\n     \n    a<-rma(y=data$ES, vi=data$var, data=data, method=\"REML\")\n    studyinfo$ES[row]<-a$b\n    studyinfo$SE[row]<-a$se\n    studyinfo$median_SE[row]<-median(data$se)\n    }\n    \n    studyinfo$id[row]<-i\n    studyinfo$k[row]<-nrow(data)\n    studyinfo$Study[row]<-c(Study1,paste(\"Study\",i))\n    row = row + 1      \n    }\n    \n  median_k<- median(studyinfo$k)\n  maxse<-max(studyinfo$SE)\n  ylim<-c(0, maxse)\n  csize <- seq(ylim[1], ylim[2], length.out = contour.points)\n  csize[csize <= 0] <- 1e-07 * min(studyinfo$SE)\n  CI_Lim<-matrix(0, nrow=length(csize), ncol=2)\n  colnames(CI_Lim)<-c(\"lb_total\", \"ub_total\")\n  \n  for (i in 1:length(csize)){\n    CI_Lim[i,1]<-estimate-1.96*sqrt((((csize[i]^2)+out)/median_k)+tau)#add 1.96*\n    CI_Lim[i,2]<-estimate+1.96*sqrt((((csize[i]^2)+out)/median_k)+tau)\n  }\n  CI_Lim<-as.data.frame(CI_Lim)\n  \nle<-length(CI_Lim[,1])\n\n\n  \n  if ((CI_Lim[le,1])< 0) {\n    minimum=min(CI_Lim[,1])\n  } else {\n    minimum=max(CI_Lim[,1])\n  } \n  \n  if ((CI_Lim[le,2]) > 0) {\n    maximum=max(CI_Lim[,2])\n  } else {\n    maximum=min(CI_Lim[,2])\n  } \n  \n  \n  lim_minimum<-floor(minimum-0.10)\n  lim_maximum<-ceiling(maximum+0.10)\n  Axis_ES <- seq(lim_minimum, lim_maximum, by=1)\n  \n  if (size_dots==1){\n    if(numbers==1){\n  e <- ggplot(data=studyinfo, aes(x = SE, y = ES, ylim(0,maxse))) +\n    geom_point(data=studyinfo, aes(size=k)) +\n    geom_text_repel(aes(label=factor(studyinfo$k)), hjust=0, vjust=-0.40, size=geom.text.size, direction=\"x\", segment.size  = 0.2, segment.color = \"grey50\")+\n    xlab('Meta-analytic standard error') + ylab('Study mean effect')+\n    geom_hline(yintercept= estimate)+\n    geom_hline(yintercept= 0, color='grey')+\n    scale_x_reverse()+\n    scale_y_continuous(breaks=Axis_ES , limits =c(lim_minimum,lim_maximum))+\n    coord_flip()+\n    theme_bw()+\n    theme(panel.grid.major=element_blank(),\n          panel.grid.minor=element_blank(),\n          panel.border=element_blank(),\n          panel.background = element_blank(),\n          axis.line=element_line(),\n          axis.title = element_text(size=14),\n          axis.text = element_text(size=12, colour = \"black\"),\n          text=element_text(),\n          legend.position=\"none\")\n    } else {\n    e <- ggplot(data=studyinfo, aes(x = SE, y = ES, ylim(0,maxse))) +\n        geom_point(data=studyinfo, aes(size=k)) +\n        xlab('Meta-analytic standard error') + ylab('Study mean effect')+\n        geom_hline(yintercept= estimate)+\n        geom_hline(yintercept= 0, color='grey')+\n        scale_x_reverse()+\n        scale_y_continuous(breaks=Axis_ES , limits =c(lim_minimum,lim_maximum))+\n        coord_flip()+\n        theme_bw()+\n        theme(panel.grid.major=element_blank(),\n              panel.grid.minor=element_blank(),\n              panel.border=element_blank(),\n              panel.background = element_blank(),\n              axis.line=element_line(),\n              axis.title = element_text(size=14),\n              axis.text = element_text(size=12, colour = \"black\"),\n              text=element_text(),\n              legend.position=\"none\")\n    }\n  \n  } else {\n   \n     if (numbers==1){\n    e <- ggplot(data=studyinfo, aes(x = SE, y = ES, ylim(0,maxse))) +\n      geom_point() +\n      geom_text_repel(aes(label=factor(studyinfo$k)), hjust=0, vjust=-0.40, size=geom.text.size, direction=\"x\", segment.size  = 0.2, segment.color = \"grey50\")+\n      xlab('Meta-analytic standard error') + ylab('Study mean effect')+\n      geom_hline(yintercept= estimate)+\n      geom_hline(yintercept= 0, color='grey')+\n      scale_x_reverse()+\n      scale_y_continuous(breaks=Axis_ES , limits =c(lim_minimum,lim_maximum))+\n      coord_flip()+\n      theme_bw()+\n      theme(panel.grid.major=element_blank(),\n            panel.grid.minor=element_blank(),\n            panel.border=element_blank(),\n            panel.background = element_blank(),\n            axis.line=element_line(),\n            axis.title = element_text(size=14),\n            axis.text = element_text(size=12, colour = \"black\"),\n            text=element_text(),\n            legend.position=\"none\")\n    }else{\n      e <- ggplot(data=studyinfo, aes(x = SE, y = ES, ylim(0,maxse))) +\n        geom_point() +\n        xlab('Meta-analytic standard error') + ylab('Study mean effect')+\n        geom_hline(yintercept= estimate)+\n        geom_hline(yintercept= 0, color='grey')+\n        scale_x_reverse()+\n        scale_y_continuous(breaks=Axis_ES , limits =c(lim_minimum,lim_maximum))+\n        coord_flip()+\n        theme_bw()+\n        theme(panel.grid.major=element_blank(),\n              panel.grid.minor=element_blank(),\n              panel.border=element_blank(),\n              panel.background = element_blank(),\n              axis.line=element_line(),\n              axis.title = element_text(size=14),\n              axis.text = element_text(size=12, colour = \"black\"),\n              text=element_text(),\n              legend.position=\"none\")\n    }\n  }\n  \n  e <- e + geom_line(data=CI_Lim, aes(y=lb_total, x=csize), colour=\"black\")+\n    geom_line(data=CI_Lim, aes(y=ub_total, x=csize), colour=\"black\")\n  print(e)\n  \n} \n\n\n# if size_dots=1, then the size of the dots representing the study-effects will be proportional to the number of effect\n#sizes included in that study. If size_dots=0, then all dots will have the same size.\n# if numbers=1, then a number will appear next to the dot represting the study-effect indicating the number of effect\n#sizes include in that study. if numbers=0, then no number will appear.\n\nthree_funnel_study(study,ES, out,var,se, size_dots=1, numbers=1)"},{"path":"id_3LMA.html","id":"reporting-publication-bias-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.4.1.2 Reporting Publication Bias","text":"Ok, ’ve now looked two different funnel plots check publication bias. tell us, report ? Well, know funnel plot symmetrical. means publication bias may concern sample. Unfortunately, best knowledge January 2024, can’t quantify well three-level models can conventional meta-analysis.","code":""},{"path":"id_3LMA.html","id":"thats-it-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.5 That’s it!","text":"’ve now gone steps needed conduct three-level meta-analysis. Congratulations! may seem intimidating, complete step, order, simple process. think - now ) code can adapt use every three-level meta-analysis conduct future, b) code can share friends, c) can share code publication others can replicate analysis. Just think - people done write book….","code":""},{"path":"id_3LMA.html","id":"section-1","chapter":"11 Three-Level Meta-Analysis","heading":"11.5.0.1 ","text":"","code":""},{"path":"change-log.html","id":"change-log","chapter":"Change Log","heading":"Change Log","text":"February 7, 2024: Book made available online.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
